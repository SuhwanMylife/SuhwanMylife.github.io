---
layout: post
title: "ê·¸ë˜í”„ ê´€ë ¨ ì—°êµ¬ ë™í–¥ íŒŒì•…"
tags:
  - Graph
  - paper review
---

<br>

Graph ê´€ë ¨ ì—°êµ¬ ë™í–¥ íŒŒì•… ëª©ì ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ë³´ê³ ì í–ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì€ ì „ì ìœ¼ë¡œ ì•„ë˜ì˜ ì‚¬ì´íŠ¸ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. [GraphOmakase ê·¸ë˜í”„ ì˜¤ë§ˆì¹´ì„¸](https://www.graphusergroup.com/tag/graphomakase/)

<br>

<details>
<summary><b>22ë…„ 12ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">
    
  **Fair Multi-Stakeholder News Recommender System with Hypergraph ranking** [[https://arxiv.org/pdf/2012.00387.pdf](https://arxiv.org/pdf/2012.00387.pdf?ref=graphusergroup.com)]
  
  ì¶”ì²œ ì‹œìŠ¤í…œì˜ popularity biasë¼ëŠ” ë¬¸ì œë¥¼ hypergraph í˜•íƒœì˜ ê´€ê³„ì— ì¹˜ì¤‘í•œ ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ í•´ì†Œí•´ë³´ê³ ì ì‹œë„í•œ ë…¼ë¬¸
  
  **Social Recommendation System Based on Hypergraph Attention Network** [[https://downloads.hindawi.com/journals/cin/2021/7716214.pdf](https://downloads.hindawi.com/journals/cin/2021/7716214.pdf?ref=graphusergroup.com)]
  
  social ë¶„ì•¼ì—ì„œ hypergraphë¥¼ ì ìš©í•œ ë…¼ë¬¸
  
  - ê¸°ì¡´ graph ëŠ” user-item, user-userì™€ ê°™ì´ pair-wiseí•˜ê²Œ ê´€ê³„ë¥¼ ì„¤ì •í•˜ê³  ì¶”ë¡ í•˜ê¸°ì— ë³µì¡í•œ ê´€ê³„ì— ëŒ€í•´ì„œëŠ” í•œê³„ì ì´ ìˆë‹¤ê³  ì§€ì ì„ í•©ë‹ˆë‹¤. ê·¸ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ hypergraph í™œìš©
  
  **Towards Better Link Prediction in Dynamic Graphs** [[https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9](https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9?ref=graphusergroup.com)]
  
  viz â†’ dynamic networkì—ì„œ ì—£ì§€ì˜ ë¶„í¬ë¥¼ ì–´ë–»ê²Œ ì‹œê°í™”í• ì§€ ê³ ë¯¼í•˜ì‹œë˜ ë¶„ë“¤ì—ê²Œ ë„ì›€
  
  - TEA, TET plot ê°ê° 2ê°€ì§€ ì‹œê°í™”ë¥¼ í†µí•´ dynamic networkì˜ edge distribution íŒŒì•…
  - ì´ë¥¼ í†µí•´, sampling strategy ë¥¼ ê¸°íší•˜ëŠ”ê²ƒë„ ì¢‹ì•„ë³´ì„
  - Dynamic network - link prediction ì— ê´€ì‹¬ì´ ë§ìœ¼ì‹  ë¶„ë“¤ì—ê²Œ ë„ì›€
  
  **Weisfeiler and Leman Go Relational** [[https://arxiv.org/pdf/2211.17113.pdf](https://arxiv.org/pdf/2211.17113.pdf?ref=graphusergroup.com)]
  
  expressive-power, isomorphism checking
  
  ê·¸ë˜í”„ ë°ì´í„° íŠ¹ì„±ìƒ ëª¨ë‘ vertex ê·¸ë¦¬ê³  edgeë¡œ í‘œí˜„ë˜ê¸°ì—, ì§ê´€ì ìœ¼ë¡œ ë°”ë¼ë³´ë©´ vertexê°€ ë‚´ê°€ ë¶„ì„í•˜ë ¤ëŠ” vertexì¸ì§€, edgeê°€ ë‚´ê°€ ë¶„ì„í•˜ë ¤ëŠ” edgeì¸ì§€ êµ¬ë³„í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ì´ ë•Œ, unique labeling, color ë“± ìœ¼ë¡œ íŒë³„ì„ í•  ìˆ˜ ìˆëŠ” ìš”ì†Œë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.
  
  - isomorphismì— ëŒ€í•´ ê¶ê¸ˆí•˜ì…¨ìœ¼ë©°, heterogeneous(ì´ì¢…ê·¸ë˜í”„) modeling ì— ëŒ€í•´ ê¸°íší•˜ê³  ìˆìœ¼ì‹  ë¶„ë“¤ì´ë©´ ë„ì›€
  
  **Generalized Laplacian Positional Encoding for Graph Representation Learning** [[https://arxiv.org/pdf/2210.15956.pdf](https://arxiv.org/pdf/2210.15956.pdf?ref=graphusergroup.com)]
  
  ì„ë² ë”© ê³µê°„, ì»´í“¨í„°ê°€ í•´ë‹¹ ë°ì´í„°ë¥¼ ì´í•´í•  ë•Œ ì •ë³´ì†ì‹¤ì—†ì´ ì˜ ì´í•´í•˜ê²Œë” ë•ê¸° ìœ„í•´ ê³ ì•ˆëœ ì—¬ëŸ¬ ë°©ë²• ì¤‘ í•˜ë‚˜ì¸ positional-encodingì— ëŒ€í•´ ì´ì•¼ê¸°
  
  **A diffusion model for protein design** [[https://www.bakerlab.org/2022/11/30/diffusion-model-for-protein-design/](https://www.bakerlab.org/2022/11/30/diffusion-model-for-protein-design/?ref=graphusergroup.com)]
  
  60ì—¬ì¥ ê°€ê¹Œì´ë˜ëŠ” ë°±ì„œë¥¼ í†µí•´ DDPM ì¦‰, diffusion model with Graph(protein) ì„¤ëª…
  
  - Protein ê´€ë ¨í•´ì„œ generated-modelì— ê´€ì‹¬ìˆìœ¼ì‹  ë¶„ë“¤ì€ ë³¸ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì°¸ì¡°í•˜ì…”ì„œ ì§„í–‰í•˜ì‹œë©´ ë§ì€ ë„ì›€
  
  **LOG conference** [[https://logconference.org/](https://logconference.org/?ref=graphusergroup.com)]
  
  log conference, machine learning on graphì— íŠ¹í™”ëœ ì»¨í¼ëŸ°ìŠ¤
  
  íŠœí† ë¦¬ì–¼ë“¤ì„ ì£¼ëª©í•´ë³´ì‹œë©´ ì¢‹ì„ê²ƒ ê°™ìŠµë‹ˆë‹¤. scalable-gnn , TF-GNN , symbol reasoning gnn ë“± êµ‰ì¥íˆ practical í•œ íŠœí† ë¦¬ì–¼ë“¤ì´ ì—¬ëŸ¬ë¶„ë“¤ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.

  <br>
    
</div>
</details>

<details>
<summary><b>22ë…„ 12ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">    
    
  **Sequential Recommendation System ì¹´ì¹´ì˜¤ ì„œë¹„ìŠ¤ ì ìš©ê¸°** [[https://if.kakao.com/2022/session/8](https://if.kakao.com/2022/session/8?ref=graphusergroup.com)]
  
  ì›¹íˆ°(ë§Œí™”) , ë¸ŒëŸ°ì¹˜(ê¸€) í”Œë«í¼ì—ì„œ â€˜sequentialí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì €ì—ê²Œ ì¶”ì²œì„ í•´ì¤€ë‹¤â€™ë¼ëŠ” ê´€ì ì„ ë‹¤ë£¬ ì´ì•¼ê¸°
  
  - ì›¹íˆ°, ë¸ŒëŸ°ì¹˜ ê°ê°ì˜ ë„ë©”ì¸ì— ë”°ë¼ time window íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ê³ , ë‚˜ë¹ ì§€ëŠ”ì§€ì— ëŒ€í•œ ì´ì•¼ê¸°
  - ì•„ë˜ GNN ì„ ì ‘ëª©í•œ ì¶”ì²œì‹œìŠ¤í…œ ë ˆí¬ê°€ ìˆì–´ ì¶”ê°€ ì „ë‹¬ë“œë¦½ë‹ˆë‹¤. ë„ì›€ë˜ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.
      - GNN with recsys [[https://github.com/wusw14/GNN-in-RS](https://github.com/wusw14/GNN-in-RS?ref=graphusergroup.com)]
  
  **Motifs-based Recommender System via Hypergraph Convolution and Contrastive Learning** [[https://arxiv.org/pdf/2109.00676.pdf](https://arxiv.org/pdf/2109.00676.pdf?ref=graphusergroup.com)]
  
  ê¸°ì¡´ì˜ node-node(pair-wise) pattern miningì´ ì•„ë‹Œ, node-(mutli)node pattern miningì˜ ì¥ì ì„ recommender systemì—ì„œ í™œìš©í•´ë³´ê³ ì ì‹œë„í•œ ë…¼ë¬¸
  
  - purchase(íŠ¹ì • ì•„ì´í…œì„ ë™ì‹œì— êµ¬ë§¤í•˜ì˜€ìœ¼ë‚˜, êµë¥˜ê°€ ì—†ëŠ” ìœ ì €) , joint(íŠ¹ì • ì•„ì´í…œì„ ë™ì‹œì— êµ¬ë§¤í•˜ì˜€ìœ¼ë©°, êµë¥˜ê°€ ìˆëŠ” ìœ ì €), social(í‰ì†Œ êµë¥˜ê°€ ìˆëŠ” ìœ ì €ë“¤ ëª¨ì„) 3ê°€ì§€ ì¢…ë¥˜ì˜ ëª¨í‹°í”„ì—ì„œ ë°œìƒí•˜ëŠ” ì •ë³´ë¥¼ í™œìš©í•´ì„œ ì¶”ì²œì‹œìŠ¤í…œì— ì ìš©
  - ì¤€ì§€ë„í•™ìŠµ , ëª¨í‹°í”„ , í•˜ì´í¼ê·¸ë˜í”„, ì¶”ì²œì‹œìŠ¤í…œ ê·¸ë¦¬ê³  gnn ì— ëŒ€í•´ ê´€ì‹¬ìˆìœ¼ì‹ ë¶„ë“¤ì€ ë³¸ ë…¼ë¬¸ì„ í†µí•´ ì»´íŒ©íŠ¸í•˜ê²Œ ì´í•´í•˜ì‹¤ ìˆ˜ ìˆì„ê±°ë¼ ìƒê°ë˜ì–´ ì¶”ì²œ
  
  **Mining Social-Network Graphs** [[http://infolab.stanford.edu/~ullman/mmds/ch10n.pdf](http://infolab.stanford.edu/~ullman/mmds/ch10n.pdf?ref=graphusergroup.com)]
  
  practical graph mining , ë³µì¡ê³„ ë„¤íŠ¸ì›Œí¬ í˜¹ì€ ê·¸ë˜í”„ë§ˆì´ë‹ì˜ ì›ë¡ ì ì¸ í…Œí¬ë‹‰ìœ¼ë¡œë¶€í„° ë°œìƒí•œ ìˆ˜ì¹˜ë“¤ì´ ì–´ë–»ê²Œ í•´ì„ë˜ëŠ”ì§€ì— ëŒ€í•´ ì´í•´í•˜ê³  ì‹¶ìœ¼ì‹  ë¶„ë“¤. (íŠ¹íˆ, ì»¤ë®¤ë‹ˆí‹° ë””í…ì…˜ ì•Œê³ ë¦¬ì¦˜ ë° spectral clustering , lapalcian matrix ê°€ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ê¶ê¸ˆí•˜ì‹ ë¶„ë“¤)
  
  - ì–‘ì´ ìƒë‹¹í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ ë¶€ë¶„ì˜ conclusion ìš”ì•½ ë²„ì „ì„ ì½ì–´ë³´ì‹ í›„, ê´€ì‹¬ìˆëŠ” ë¶€ë¶„ì„ ê³¨ë¼ë³´ì‹œëŠ”ê±¸ ì¶”ì²œ
  
  **Session-based Recommendation with Hypergraph Attention Networks** [[https://arxiv.org/abs/2112.14266](https://arxiv.org/abs/2112.14266?ref=graphusergroup.com)]
  
  ì„¸ì…˜ë§ˆë‹¤ì˜ ì •ë³´ë“¤ì„ í•˜ì´í¼ê·¸ë˜í”„ í˜•íƒœë¡œ ë§Œë“¤ì–´ ì¤€ ë’¤, ì¶”ì²œì‹œìŠ¤í…œì— í™œìš©í•´ë³´ëŠ” ë…¼ë¬¸
  
  - Session-based task: ìœ ì €ê°€ ë‹¤ìŒ ì„¸ì…˜ì— ì–´ë–¤ í–‰ë™ (êµ¬ë§¤ , ì°œ ë“±) ì„ í• ì§€ ì´ì „ ì„¸ì…˜ì—ì„œì˜ ìœ ì € í–‰ë™ì„ ë¶„ì„í•´ì„œ ì¶”ë¡ í•˜ëŠ” ë¬¸ì œ
  - ì´ ë•Œ ì„¸ì…˜ì—ì„œ ë°œìƒí•˜ëŠ” ì •ë³´ë¥¼ contextual informationì´ë¼ ë¶€ë¦„
  - Session-based ê³¼ hypergraph combinatioin, dynamic graph vs. hypergraph ê´€ì ì— ëŒ€í•´ í˜¸ê¸°ì‹¬ì´ ìˆìœ¼ì‹  ë¶„ë“¤ì—ê²Œ ì¶”ì²œ
  
  **You Can Have Better Graph Neural Networks by Not Training Weights at All: Finding Untrained GNNs Tickets** [[https://openreview.net/forum?id=dF6aEW3_62O](https://openreview.net/forum?id=dF6aEW3_62O&ref=graphusergroup.com)]
  
  untrained subnetwork ë¥¼ efficient í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œ ë…¼ë¬¸
  
  ëª¨ë¸ì˜ weightê°€ ì˜ í•™ìŠµëœ subnetworkë¥¼ ì°¾ëŠ” ë°©ì‹ì— ëŒ€í•´ ì–¸ê¸‰
  
  - graph ë°ì´í„° ì¸¡ë©´ì—ì„œì˜ í•œê³„ì ì¸ sparsity ì„ ê·¹ë³µí•˜ë©´ì„œ ì–´ë–»ê²Œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ”ì§€ì— ëŒ€í•œ ë°©ë²• ë˜í•œ ì–¸ê¸‰
  
  **êµ‰ì¥íˆ í¥ë¯¸ë¡œìš´ ë…¼ë¬¸ì¸ì§€ë¼ ê´€ì‹¬ì‚¬ ë¶ˆë¬¸í•˜ê³  í•œ ë²ˆ ì½ì–´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.**
  
  - í˜„ì—…ì—ì„œ GNN ì„ ì ìš©í•˜ê¸° ìœ„í•´ ìµœì ì˜ network ë§Œì„ ì¶”ì¶œí•˜ëŠ” ê²ƒì— ê´€ì‹¬ìˆìœ¼ì‹ ë¶„ë“¤ , over-smoothing ë¬¸ì œ ë•Œë¬¸ì— ê³¨ë¨¸ë¦¬ë¥¼ ì•“ê³  ê³„ì‹œëŠ” ë¶„ë“¤ ì—ê²Œ ì¶”ì²œ
  
  **Neighborhood-aware Scalable Temporal Network Representation Learning** [[https://openreview.net/pdf?id=EPUtNe7a9ta](https://openreview.net/pdf?id=EPUtNe7a9ta&ref=graphusergroup.com)]
  
  - link prediction ì—ì„œ ê³ ì§ˆì ì¸ ë¬¸ì œì£ . temporary, time-wise ë“± ì‹œê°„ì— ë”°ë¼ ë³€í˜•ë˜ëŠ” ê·¸ë˜í”„ì˜ structural information ì„ ì–´ë–»ê²Œ ë‹¤ë£°ê²ƒì¸ì§€ì— ëŒ€í•´ ë‹¤ë£¬ ë…¼ë¬¸
  - dynamic graph representation learning ê·¸ë¦¬ê³  link prediction task ì— ëŒ€í•´ ê´€ì‹¬ìˆìœ¼ì‹ ë¶„ë“¤ì—ê²Œ ì¶”ì²œ

  <br>
    
</div>
</details>

<details>
<summary><b>22ë…„ 12ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">     
    
  **TGL: A General Framework for Temporal GNN Training on Billion-Scale Graphs**
  
  billion-scale ì„ ê°€ì§„ ê·¸ë˜í”„ë“¤ì„ ì–´ë–»ê²Œ í•™ìŠµí•˜ê³  ì¶”ë¡ í• ì§€ì— ëŒ€í•´ ë§ì´ ê³ ë¯¼í•˜ì‹¤í…ë°ìš”. ê·¸ ê°€ì´ë“œë¼ì¸ , ë ˆí¼ëŸ°ìŠ¤ë¡œì¨ ì¢‹ì€ ì°¸ê³ ì„œê°€ ë  ë…¼ë¬¸
  
  - node memory, attention aggregator, temporal sampler ê·¸ë¦¬ê³  multi-gpu(parallel-sampling)ì„ ì–´ë–»ê²Œ í•˜ëŠ”ì§€ë“± í˜„ì—…ì—ì„œ ë§ˆì£¼í•˜ì‹¤ ë§ì€ ê³ ë¯¼ë“¤ì„ ë³¸ ë…¼ë¬¸ì—ì„œ ëª…ì¾Œí•˜ê²Œ í’€ì–´ë‚´ê³  ìˆìŠµë‹ˆë‹¤.
  - ë…¼ë¬¸ì„ ì½ë‹¤ë³´ì‹œë©´, binary search, pointer ë“±ì˜ ë°ì´í„° ìë£Œêµ¬ì¡° ì¸¡ë©´ì—ì„œ ì ‘ê·¼í•˜ëŠ” ì„¹ì…˜ì´ ê°„ê°„ì´ ìˆê¸°ì— ë””í…Œì¼í•œ ì´í•´ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ ì ì‹œ ë°ì´í„° ìë£Œêµ¬ì¡°ë¥¼ ë³µìŠµí•˜ê³  ì˜¤ì‹œëŠ”ê±¸ ì¶”ì²œ
  
  **APAN: Asynchronous Propagation Attention Network for Real-time Temporal Graph Embedding**
  
  MLops ê´€ë ¨ lecture ì¸ cs329S ê³µë¶€ ì¤‘ ë°œê²¬í•œ ë…¼ë¬¸ì…ë‹ˆë‹¤. ì €ë„ ë‚´ë…„ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ë¡œ gnn with web deploymentí•´ë³´ëŠ” ê²Œ ëª©í‘œë¼ ë˜ê²Œ ë°˜ê°€ì› ê³ , ë…ìë¶„ë“¤ ì ˆë°˜ê°€ê¹Œì´ í˜„ì—…ì— ê³„ì‹ ë¶„ë“¤ì´ì‹œê¸°ì— ë„ì›€ë˜ì‹¤ê±°ë¼ ìƒê°ë˜ì–´ ì¤€ë¹„
  
  â€˜since users cannot tolerate the high latency of neighbor query in a giant graph database, deploying a synchronous CTDG model in online payment platform is almost worthlessâ€™ ë¼ëŠ” ì–´ì ˆì„ ë…¼ë¬¸ì— ëª…ì‹œí•´ë†“ì€ë§Œí¼ ì‚°ì—… ê´€ì ì—ì„œ ì˜ í’€ì–´ë‚¸ ë…¼ë¬¸
  
  **Residual Network and Embedding Usage: New Tricks of Node Classification with Graph Convolutional Networks**
  
  node-classification ì—ì„œì˜ Efficiency trickë“¤ì„ ëª¨ì•„ë†“ì€ ë…¼ë¬¸
  
  baseline ì„ êµ¬í˜„ í›„ ì„±ëŠ¥ì´ ë§ˆìŒì— ë“¤ì§€ ì•Šì„ ë•Œ ì°¸ê³ í•˜ì‹œë©´ ì¢‹ì„ ë…¼ë¬¸
  
  **Pay Attention to MLPs**
  
  transformer êµ¬ì¡°ê°€ ë”¥ëŸ¬ë‹ modelì—ì„œ hegemony ë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  í‘œí˜„í•´ë„ ê³¼ì–¸ì´ ì•„ë‹ë§Œí¼ ë§ì€ ì‚°ì—…ì—ì„œ í™œìš©ë˜ê³  ìˆìŒ
  
  transformerì˜ í•µì‹¬ ì •ë³´ì¸ positional encodingì„ spatial gating unitì´ë¼ëŠ” ê°œë…ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤ëŠ” ì•„ì´ë””ì–´ê°€ ì£¼ì¸ ë…¼ë¬¸
  
  **Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods**
  
  ë³µì¡ê³„ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ë¶„ì„í•  ë•Œ, ì£¼ë¡œ í™œìš©ë˜ëŠ” ì§€í‘œ ì¤‘ í•˜ë‚˜ì¸ homophilyë¥¼ large scale gnnì— ì°¨ìš©í•œ ë…¼ë¬¸
  
  homophilyì— ì˜ì¡´ì ì¸ ë°ì´í„°ë“¤ì€ ì£¼ë³€ ì´ì›ƒì˜ ì •ë³´ë¡œë¶€í„° ë§ì€ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸°ìœ„í•´, ë…¸ë“œì˜ ì •ë³´ì™€ ê·¸ë˜í”„ êµ¬ì¡°ì  ì •ë³´ë¥¼ ê°ê° ë…ë¦½ ì ìš©í•œë‹¤ëŠ”ê²Œ ë³¸ ì•„ì´ë””ì–´ì˜ í•µì‹¬
  
  - **homophily**ë¥¼ ê°„ë‹¨í•˜ê²Œ ë§ì”€ë“œë¦¬ë©´, â€˜ìœ ìœ ìƒì¢…â€™ ì´ë¼ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ì´ë¥¼ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ì—ì„œ ìƒê°í•´ë³´ë©´ â€˜ë¹„ìŠ·í•œ ì‚¬ëŒ(ë…¸ë“œ)ë“¤ ë¼ë¦¬ëŠ” ì—°ê²°(link)ë˜ì–´ ìˆì„ê²ƒì´ë‹¤.â€™ ë¼ê³  ê°€ì •í•˜ë©° ì¸¡ì •í•˜ëŠ” ì§€í‘œ

  <br>
    
</div>
</details>

<details>
<summary><b>23ë…„ 1ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">    
    
  **Scalable Graph Transformers for Million Nodes**
  
  message passingì„ hopbyhopìœ¼ë¡œ ì§„í–‰í•˜ë©° information resort ê°€ í•„ìš”í•œ gnn ëŒ€ë¹„(local feature aggregation), all feature aggregationì´ ê°€ëŠ¥í•œ graph transformerëŠ” local + global feature aggregationì´ ëª¨ë‘ ê°€ëŠ¥í•˜ë‹¨ ê±°ì£ . ì´ë¥¼ í†µí•´, â€œover-squashing ë¬¸ì œì™€ graph task flexibility ì—ì„œ ê°•ë ¥í•˜ë‹¤.â€ë¼ê³  ë§í•©ë‹ˆë‹¤.
  
  - ë…¼ë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” Transformer, Performer, gumble-softmax, etc.. ìˆ˜í•™ì ì¸ í…Œí¬ë‹‰ì´ ë§ì´ ë°˜ì˜ë˜ì–´ìˆê¸°ì—, â€˜ì´ëŸ° ì•„í‚¤í…ì³ê°€ ìˆêµ¬ë‚˜~ ê·¸ë˜í”„ì˜ global featureë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì‹œë„ë“¤ì´ ìˆêµ¬ë‚˜â€™ë¼ëŠ” ì¸¡ë©´ìœ¼ë¡œ ê°€ë³ê²Œ ë³´ì‹œëŠ” ê±¸ ì¶”ì²œ
  
  **BGL: GPU-Efficient GNN Training by Optimizing Graph Data I/O and Preprocessing**
  
  GPU-efficientë¥¼ ìœ„í•´ feature retrievingê³¼ subgraph sampling(neighborhood sampling)ì„ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€ì— ëŒ€í•´ ê¸°ìˆ í•œ ë…¼ë¬¸
  
  - data I/O size (batch ë§ˆë‹¤ subgraph ë¥¼ ê°€ì ¸ì˜¤ê³  , ê·¸ subgraph ì˜ node featureë¥¼ ê°€ì ¸ì™€ì•¼ í•¨)ëŠ” êµ‰ì¥íˆ í° ë°˜ë©´ì—, ëª¨ë¸ (GraphSAGEëŠ” node sampling ì´í›„ mean ë“± parameterê°€ ì ìŒ.)ì€ ê°€ë³ë‹¤. ê·¸ë ‡ê¸°ì— huge gapì´ ë°œìƒí•˜ë©´ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì—°ì‚°í•˜ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ë¬¸ì œë¡œ ì •ì˜í•˜ê³ , ê·¸ê²ƒì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ì‹ì„ ì œì•ˆ
  - ë‚´ìš©ì´ ì›Œë‚™ ë°©ëŒ€í•˜ê³ , ì»´í“¨í„° ê³µí•™ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì´ ë§ì´ í•„ìš”í•˜ì—¬ ì½ìœ¼ì‹¤ ë•Œ ë‹¤ì†Œ ì§€ë£¨í•˜ì‹œê³  ì–´ë µë‹¤ê³  ìƒê°í•˜ì‹¤ ìˆ˜ë„ ìˆê² ìŠµë‹ˆë‹¤. í—ˆë‚˜, ê·¸ë§Œí¼ ìµœì í™”ì— ëŒ€í•œ ì§€ì‹ì„ ì˜ ë‚˜íƒ€ë‚¸ ì•„ì´ë””ì–´ë¡œì¨ ì¶©ë¶„í•œ ê°€ì¹˜ê°€ ìˆê¸°ì— graph, scalability ë“±ì— ê´€ì‹¬ ìˆìœ¼ì‹  ë¶„ë“¤ì€ ì½ì–´ë³´ì‹œëŠ” ê±¸ ì¶”ì²œ
  
  **Using Graph Learning for Personalization**
  
  Graphë¥¼ Recommender system ì— ì ìš©í•˜ë©´ ì–´ë–¤ ì ì´ ìœ ë¦¬í•œì§€ ê·¸ë¦¬ê³  í•´ì™¸ ìœ ìˆ˜ ê¸°ì—…ë“¤ì€ ì–´ë–»ê²Œ ì ìš©ì„ í•˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…
  
  - GNNì´ ë§ì€ ê´€ì‹¬ì„ ë°›ê³  ìˆëŠ”ë° ì™œ ìœ ë… ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ë§ì´ ì–¸ê¸‰ë˜ëŠ”ê°€?ë¼ëŠ” í˜¸ê¸°ì‹¬ì´ ìˆìœ¼ì‹  ë¶„ë“¤ì—ê²Œ ì¶”ì²œ
  
  **Chartalist: Labeled Graph Datasets for UTXO and Account-based Blockchains**
  
  ë¸”ë¡ì²´ì¸ì˜ transparency databaseì˜ í˜•íƒœê°€ ê²°êµ­ linked list ì´ê¸°ì—, ì—°ê²°ë¡œì¨ ìì‚°ë“¤ì˜ íë¦„ì„ ë¶„ì„í•  ìˆ˜ ìˆë‹¤ëŠ” ê±°ì£ . ê·¸ë¦¬í•˜ì—¬, graph ì˜ ì¥ì ì¸ ë…¸ë“œ-ë…¸ë“œë¥¼ ì§€ê°‘-ì§€ê°‘ ë“±ìœ¼ë¡œ ë§µí•‘í•´ì„œ í™œìš©í•˜ë©´ íš¨ìœ¨ì ì´ê¸°ì— ì£¼ë¡œ graph ì¸¡ë©´ìœ¼ë¡œ ì ‘ê·¼í•˜ê³¤ í•©ë‹ˆë‹¤.
  
  - financial network analysisë¥¼ í•´ë³´ê³  ì‹¶ì—ˆìœ¼ë‚˜ ì—¬ëŸ¬ í•œê³„ë“¤ ë•Œë¬¸ì— ë³´ë¥˜í•˜ì…¨ë˜ ë¶„ë“¤ì—ê²Œ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
  
  **ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest**
  
  ì‚°ì—…ì—ì„œ ì ìš©í•˜ê³  ìˆëŠ” gnn ì˜ ëŒ€í‘œì  ì‚¬ë¡€ì¸ â€˜PINSAGEâ€™ì— ëŒ€í•´ ë‹¤ë“¤ ì•Œê³  ê³„ì‹¤í…ë°ìš”. ê·¸ ëª¨ë¸ì„ ì¢€ ë” í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ë¥¼ ì°¨ìš©í•œ ì•„ì´ë””ì–´
  
  **Next-item Recommendation with Sequential Hypergraphs**
  
  ì¶”ì²œ ì˜ì—­ì—ì„œ í•˜ì´í¼ê·¸ë˜í”„ê°€ ì–´ë–¤ì‹ìœ¼ë¡œ í™œìš©ì´ ë˜ëŠ”ì§€ë¥¼ ê¸°ìˆ 
  
  - ìœ ì €ì˜ í–‰ë™ ë°œìƒ ì „/í›„ì— ëŒ€í•´ì„œì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ ì–¸ê¸‰í•˜ë©°, ê·¸ ì „/í›„(window , Time Granularity) ë¥¼ íŒŒì•…í•˜ëŠ”ê²Œ í•µì‹¬ì´ë©°, ê·¸ contextë¥¼ í•˜ì´í¼ê·¸ë˜í”„ë¥¼ í†µí•´ ì¶”ì¶œí•˜ëŠ”ê²ƒì´ ì¢‹ë‹¤ ë¼ê³  ì£¼ì¥

  <br>
    
</div>
</details>

<details>
<summary><b>23ë…„ 1ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">
    
  **Anomaly Detection in Multiplex Dynamic Networks: from Blockchain Security to Brain Disease Prediction** [[https://openreview.net/pdf?id=UDGZDfwmay](https://openreview.net/pdf?id=UDGZDfwmay&ref=graphusergroup.com)]
  
  Anomaly detection with GNN ì•„ì´ë””ì–´ ì…ë‹ˆë‹¤. brain, blockchain, ì¶”ì²œ, í˜‘ì—… ì—ì„œ ë°œìƒí•˜ëŠ” anomaly edge interactionì„ unsupervised mannerë¡œ í•´ê²°í•´ë³¸ë‹¤ê°€ ë…¼ë¬¸ì˜ ë…¸ë²¨í‹°
  
  - ë˜ê²Œ ì‹¬í”Œí•œ ì•„ì´ë””ì–´ ì…ë‹ˆë‹¤. í˜„ì—…ì—ì„œ êµ¬í˜„í•˜ê¸°ì—ë„ ë³„ ë¬´ë¦¬ì—†ì–´ë³´ì´ê¸°ì—, anomaly deteciton with gnnì— ëŒ€í•œ ë‹ˆì¦ˆê°€ ìˆìœ¼ì‹ ë¶„ë“¤ì„ ì´ë¥¼ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ì¡ê³  ì§„í–‰í•´ë³´ì‹œëŠ”ê²Œ ì–´ë–¨ê¹Œ ì‹¶ë„¤ìš”.
  
  **Influencer Detection with Dynamic Graph Neural Networks** [[https://openreview.net/pdf?id=LJeEO2lC_6](https://openreview.net/pdf?id=LJeEO2lC_6&ref=graphusergroup.com)]
  
  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ dynamic graphë¥¼ ì–´ë–»ê²Œ í™œìš©í•´ë³¼ ê²ƒì¸ì§€ì— ëŒ€í•œ ê³ ë¯¼ì„ í† ëŒ€ë¡œ gnnì„ í™œìš©í•œ ì‚¬ë¡€ ë° ì•„ì´ë””ì–´
  
  **Time-Evolving Conditional Character-centric Graphs for Movie Understanding** [[https://openreview.net/pdf?id=NXnSr_uXgh](https://openreview.net/pdf?id=NXnSr_uXgh&ref=graphusergroup.com)]
  
  ë°ì´í„° ì ìš© ë„ë©”ì¸ì´ íŠ¹ì´í•œ ë…¼ë¬¸ì…ë‹ˆë‹¤. â€˜íŠ¹ì • ë¹„ë””ì˜¤ ë‚´ì—ì„œ ì‚¬ë¬¼ ê³¼ ì‚¬ëŒ ê°„ì˜ ê´€ê³„â€™ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ì—¬ VQA(video question answering) ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ê³ ì ì ‘ê·¼í•œ ë…¼ë¬¸
  
  - ê·¸ë˜í”„ í˜•ì‹ì˜ ë°ì´í„° ë¿ë§Œ ì•„ë‹ˆë¼, í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë“±ì˜ ë°ì´í„°ë¡œë¶€í„° ê´€ê³„ë¥¼ ë¶€ì—¬í•˜ì—¬ ì„±ëŠ¥í–¥ìƒì„ ê¾€í•˜ëŠ” ì•„ì´ë””ì–´ë“¤ì´ ìœ ëª… í•™íšŒì—ì„œ ì‹¬ì‹¬ì¹˜ ì•Šê²Œ ë³´ì´ê³¤ í•˜ëŠ”ë°ìš”. ê·¸ë§Œí¼ ë°ì´í„° ê°„ì˜ edge(ê´€ê³„)ë¥¼ ì–´ë–»ê²Œ ë¶€ì—¬í•´ì•¼ í•©ë¦¬ì ì¸ì§€ íš¨ê³¼ì ì¸ì§€ì— ëŒ€í•œ ë…¼ì˜ ë˜í•œ ì¤‘ìš”í•´ ë³´ì…ë‹ˆë‹¤. ì£¼ë¡œ attention scoreë¥¼ í†µí•´ ê·¸ ì¤‘ìš”ë„ë¥¼ ì‚°ì¶œí•˜ê³  edgeë¥¼ generationí•´ì£¼ê³¤ í•˜ëŠ”ë°ìš”. ê´€ì‹¬ìˆìœ¼ì‹ ë¶„ë“¤ì€ [zero-shot knowledge graph vqa] í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œëŠ”ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.
  
  **Hypernetwork science via high-order hypergraph walks** [[https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-020-00231-0](https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-020-00231-0?ref=graphusergroup.com)]
  
  í•˜ë£¨ì— ëª¨ë‘ ì •ë…í•˜ê¸°ë³´ë‹¤ í•˜ì´í¼ê·¸ë˜í”„ë¥¼ ë¶„ì„ ê·¸ë¦¬ê³  ì˜ˆì¸¡ìœ¼ë¡œ í™œìš©í•´ë³´ê³  ì‹¶ë‹¤ í•˜ì‹¤ë•Œ, í•„ìš”í•œ ë¶€ë¶„ë§Œ ë³´ì‹œëŠ”ê±¸ ì¶”ì²œ
  
  - network science ì¸¡ë©´ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” centrality measurement, component ë“±ê³¼ ê°™ì€ ìš”ì†Œë“¤ì´ ê·¸ëŒ€ë¡œ ì ìš©ë˜ì–´ ìˆìœ¼ë©°, ê·¸ ìš”ì†Œë“¤ì˜ ê°’ì´ ì‚°ì¶œë˜ì—ˆì„ ë•Œ ì–´ëŠ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€, ê·¸ë¦¬ê³  pair-wise(vanilla network)ì¼ ë•Œë‘ ì–´ëŠ ì°¨ì´ê°€ ìˆëŠ”ì§€ ë“±ì„ ì˜ ì„¤ëª…
  
  **PyTorch + Rapids RMM: Maximize the Memory Efficiency of your Workflows** [[https://medium.com/rapids-ai/pytorch-rapids-rmm-maximize-the-memory-efficiency-of-your-workflows-f475107ba4d4](https://medium.com/rapids-ai/pytorch-rapids-rmm-maximize-the-memory-efficiency-of-your-workflows-f475107ba4d4?ref=graphusergroup.com)]
  
  Rapids ê³„ì—´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ê³¤ ìˆìœ¼ë‚˜, ê°„ê°„ì´ ë“±ì¥í•˜ëŠ” OOM ë¬¸ì œë¥¼ ê²ªëŠ” ë¶„ë“¤ì—ê²Œ ë„ì›€ì´ ë ë§Œí•œ ê¸€
  
  - íŠ¹íˆ, gnnë¥¼ í™œìš©í•´ì„œ multi-modal learningë¥¼ ì§„í–‰í•˜ì‹œë ¤ëŠ” ë¶„ë“¤ì€ ê°ê¸° ë‹¤ë¥¸ featureë“¤ì„ node featureí˜¹ì€ edge featureë¡œ ì£¼ì…í•˜ëŠ”ê³¼ì •ì„ ê²ªìœ¼ì‹¤ í…ë°ìš”. ì´ ë•Œ, í™œìš©í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

  <br>
    
</div>
</details>

<details>
<summary><b>23ë…„ 1ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">
    
  **Examining graph neural networks for crystal structures: limitations and opportunities for capturing periodicity** [[https://arxiv.org/abs/2208.05039](https://arxiv.org/abs/2208.05039?ref=graphusergroup.com)]
  
  ì›ì ë°°ì—´ì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ ê°•ì¡°í•˜ë©° material ì‚°ì—…ì—ì„œì˜ GNNì˜ ì—­í• ì— ëŒ€í•´ ë…¼ì˜
  
  - ê³¼ì—° GNNì´ ê¸°ì¡´ human-designed descriptorsì˜ íŠ¹ì„± ì •ëŸ‰í™”ë¥¼ ì˜ í•  ê²ƒì¸ì§€ê°€ ì£¼ research question
  - material, physicsì— ê´€ì‹¬ìˆëŠ” ë¶„ë“¤ì´ ë³´ì‹œë©´ ì¢‹ì„ ë…¼ë¬¸ ê°™ìŠµë‹ˆë‹¤. ì™œ gnnì´ lattice êµ¬ì¡°ì—ì„œ ê°•í•œê°€ë¶€í„° ì‹œì‘í•´ì„œ ì–´ë–¤ ìš”ì†Œë“¤ì´ predictionì— ìœ ë¦¬í•œì§€ì™€ ê°™ì€ ì „ë°˜ì ì¸ ì²­ì‚¬ì§„ì„ íŒŒì•…í•˜ê¸°ì— ì¢‹ì€ ë…¼ë¬¸ì´ë¼ ìƒê°
  
  **On the Ability of Graph Neural Networks to Model Interactions Between Vertices** [[https://arxiv.org/abs/2211.16494](https://arxiv.org/abs/2211.16494?ref=graphusergroup.com)]
  
  ê¸°ì¡´ì—ëŠ” ì–´ë–¤ vertexê°€ removedë˜ì—ˆì„ ë•Œ, prediction performanceê°€ ì˜¤ë¥´ê³  ë‚´ë¦¬ê³ ë¥¼ ê´€ì°°í•˜ë©° ì¤‘ìš”ë„ë¥¼ ì‚°ì •í–ˆë‹¤ë©´, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” verteë¥¼ ì—°ê²°í•˜ëŠ” edgeì˜ ì¤‘ìš”ë„ë¥¼ ì‚°ì •í•˜ê¸° ìœ„í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œ
  
  - Walk Index Sparsification(WIS) ë¼ëŠ” ì•„ì´ë””ì–´
  - large graph dataset (w GNN model training) ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì ìš©í•˜ê¸° ìœ„í•´ ê³ ë¯¼í•˜ê³  ê³„ì‹  ë¶„ë“¤ì—ê²Œ ë„ì›€
  
  **Temporal Graph Learning in 2023** [[https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2](https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2?ref=graphusergroup.com)]
  
  dynamic, temporal graphì˜ ê¸°ë³¸ì„œë¼ ìƒê°í•´ë„ ë ë§Œí¼ í•µì‹¬ ë‚´ìš©ë“¤ì„ ì˜ ì •ë¦¬í•´ë†“ì€ í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.
  
  - ê·¸ë˜í”„ í˜•íƒœì˜ ë°ì´í„°ì—ì„œ ì‹œê°„ì— ëŒ€í•œ ì •ë³´ë„ ë°˜ì˜ë˜ì–´ ìˆì„ ë•Œ, ì–´ë–¤ ì ‘ê·¼ë²•ì´ ì¢‹ì„ì§€ ê³ ë¯¼í•˜ê³  ê³„ì‹  ë¶„ë“¤ì—ê²Œ ë„ì›€
  
  **Multi-behavior Recommendation with Graph Convolutional Networks** [[https://peterjin.me/Multi-behaviour](https://peterjin.me/Multi-behaviour?ref=graphusergroup.com)Â Recommendation with Graph Convolutional Networks.pdf]
  
  ìœ ì €ì˜ ë‹¤ì–‘í•œ í–‰ë™ë“¤ì„ ê·¸ë˜í”„ í˜•íƒœë¡œ í‘œí˜„í•˜ì—¬ ì¶”ì²œì‹œìŠ¤í…œì— í™œìš©
  
  - ë‹¤ì–‘í•œ í–‰ë™ë“¤ì´ë¼ í•¨ì€ ì •ì˜í•˜ê¸°ì— ë”°ë¼ ë¬´ìˆ˜íˆ ë§ê² ìœ¼ë‚˜ ì—¬ê¸°ì—ì„  click, cart, purchase 3ê°€ì§€ë§Œì„ ì„ ì •í•˜ì—¬ ì ìš©
  - ì´ ë…¼ë¬¸ì—ì„œ ì£¼ì˜ê¹Šê²Œ ë³´ë©´ ì¢‹ì„ í¬ì¸íŠ¸ëŠ” 1. ë‹¤ì–‘í•œ í–‰ë™ë“¤ì´ ìœ ì €ì˜ ì¶”ì²œì— ì–´ë–»ê²Œ ê¸°ì—¬í•˜ëŠ”ê°€ì— ëŒ€í•œ ë…¼ë¦¬ ì „ê°œ 2. user-item graph ë¿ë§Œì•„ë‹ˆë¼, item-item graphë¥¼ ì„¤ê³„í•˜ì—¬ ëŒ€ì²´ì¬, ë³´ì™„ì¬ ì¸¡ë©´ìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ” ë…¼ë¦¬ ì´ìƒ ë‘ ê°€ì§€ë¥¼ ìœ ì˜ê¹Šê²Œ ë³´ì‹œê³  ì ìš©í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

  <br>
    
</div>
</details>
    
<details>
<summary><b>23ë…„ 1ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">    
    
  **Static and dynamic robustness**(ì¶œì²˜ : Boccaletti, Stefano, et al. "Complex networks: Structure and dynamics."Â *Physics reports*Â 424.4-5 (2006): 175-308.APA)
  
  ë„¤íŠ¸ì›Œí¬ ì§€ì‹ ì¤‘ â€˜robustnessâ€™ì— ëŒ€í•œ ì„¤ëª… 
  
  **Graph Fusion in Reciprocal Recommender Systems** [[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025747](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025747&ref=graphusergroup.com)]
  
  reciprocal recommender system
  
  ì´ì»¤ë¨¸ìŠ¤ì—ì„œì˜ ì¶”ì²œì‹œìŠ¤í…œì€ ìœ ì €-ì•„ì´í…œ ê°„ì˜ â€˜í´ë¦­â€™ ì—¬ë¶€ë¥¼ labelë¡œ ë‘ê³  prediction í–ˆë‹¤ë©´, reciprocal recommender system ëŠ” ìœ ì €-ìœ ì € ê°„ì˜ â€˜matchingâ€™ ì—¬ë¶€ë¥¼ label ë¡œ ë‘¡ë‹ˆë‹¤. ìƒí˜¸ì‘ìš©ì´ ë°œìƒí•˜ëŠëƒ ì•„ë‹ˆëƒ ë¡œ êµ¬ë³„í•˜ì‹¤ìˆ˜ ìˆì„ê±° ê°™ë„¤ìš”.
  
  - ì•„ì´ë””ì–´ê°€ ì‹¬í”Œí•˜ê³  í¥ë¯¸ë¡œì›Œì„œ ì†Œê°œì‹œì¼œ ë“œë¦½ë‹ˆë‹¤. íŠ¹íˆ, negative sampling ì„ ì—¬ê¸°ì—ì„  ì–´ë–»ê²Œ í–ˆì„ì§€ ìœ ë…í•˜ì‹œë©´ì„œ ë…¼ë¬¸ ë³´ì‹œëŠ”ê±¸ ì¶”ì²œ
  
  **Feature selection: Key to enhance node classification with graph neural networks** [[https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cit2.12166](https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cit2.12166?ref=graphusergroup.com)]
  
  GNNì˜ ì„±ëŠ¥ì„ ë†’ì´ê³ ì selectorê³¼ classifier modelë¥¼ joint learningí•˜ëŠ” ì•„í‚¤í…ì³ë¥¼ ì œì•ˆ
  
  - ë³¸ ë…¼ë¬¸ì˜ ì¬ë¯¸ í¬ì¸íŠ¸ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸ì—ì„œ ì£¼ë¡œ ë°°ìš°ëŠ” lasso RFE ë“±ì„ feature selection baseline ìœ¼ë¡œ ë‘ê³  ì‹¤í—˜ë¹„êµë¥¼ í•˜ëŠ” íŒŒíŠ¸
  - ì°¸ê³ ë¡œ future workì—ì„œ ì €ìê°€ í•œê³„ì ì„ ì–¸ê¸‰í•˜ëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë°, í•œ ë²ˆ ì¬ë¯¸ì‚¼ì•„ êµ¬í˜„í•´ë³´ì‹œëŠ” ê±¸ ì¶”ì²œ
  
  **Everything is Connected: Graph Neural Networks** [[https://arxiv.org/pdf/2301.08210.pdf](https://arxiv.org/pdf/2301.08210.pdf?ref=graphusergroup.com)]
  
  GNN ì˜ í•µì‹¬ì„ ë‹´ì•„ë†“ì€ ë…¼ë¬¸ì…ë‹ˆë‹¤. í‰ì†Œ ì£¼ë³€ë¶„ë“¤ì—ê²Œ GNNì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ê³  ì‹¶ìœ¼ì…¨ë˜ ë¶„ë“¤ì´ ì°¸ê³ í•˜ì‹œë©´ ë„ˆë¬´ë‚˜ë„ ì¢‹ì„ ë¦¬ì†ŒìŠ¤
  
  - GNNì˜ í•œê³„ì ë¶€í„° ì™œ graph data ì¸ì§€ ê·¸ë¦¬ê³  gnn ì„ ê³µë¶€í•˜ê³  ìˆëŠ”ë° ìê¾¸ expressive power ë¼ëŠ” ë‹¨ì–´ê°€ ë‚˜ì˜¤ëŠ”ì§€ ì˜ë¬¸ì´ ìˆìœ¼ì…¨ë˜ ë¶„ë“¤ì´ì‹œë¼ë©´ ê·¸ í˜¸ê¸°ì‹¬ì„ ë‹¨ë²ˆì— í•´ì†Œí•´ ì¤„ ë…¼ë¬¸
  - ì—­ì‹œ ê³ ìˆ˜ë‹µê²Œ ì–´ë ¤ìš´ ê°œë…ë“¤ì„ ëª…ì¾Œí•˜ê³  ê°„ê²°í•˜ê³  ë¬´ì—‡ë³´ë‹¤ë„ ì‰½ê²Œ ì„¤ëª…ë˜ì–´ ìˆì–´ ë‘ê³  ë‘ê³  ë˜ìƒˆê¹€í•  ë…¼ë¬¸ì´ë¼ ìƒê°
  
  **Understanding Graph based similarity: Simrank, Simrank++** [[https://medium.com/@ksdave/understanding-graph-based-similarity-simrank-simrank-91619c88c336](https://medium.com/@ksdave/understanding-graph-based-similarity-simrank-simrank-91619c88c336?ref=graphusergroup.com)]
  
  structural similarityì˜ ëŒ€ëª…ì‚¬ Simrankê°€ ì—…ê·¸ë ˆì´ë“œ
  
  **Simrank**: ë…¸ë“œê°„ neighbor/connection ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ ì¸¡ì •
  
  - link analysis í•˜ì‹¤ë•Œ, pagerank ë¥¼ baseline ìœ¼ë¡œ importance ì¸¡ì •í•˜ì…¨ë˜ ë¶„ë“¤ì—ê²Œ ì¬ë¯¸ë‚œ ì†Œì‹ì´ ë  ìˆ˜ë„ ìˆê² ë„¤ìš”! Simrank í•œ ë²ˆ ì ìš©í•´ë³´ì‹œëŠ” ê±¸ ì¶”ì²œ
  
  **conference** [[https://www2023.thewebconf.org/program/tutorials/](https://www2023.thewebconf.org/program/tutorials/?ref=graphusergroup.com)]
  
  ë„ˆë¬´ë‚˜ë„ ì¬ë°ŒëŠ” íŠœí† ë¦¬ì–¼ë“¤ì´ í•œê°€ë“ì¸ WWW2023 ì†Œì‹
  
  í•˜ì´í¼ê·¸ë˜í”„ definitionë¶€í„° applicationê¹Œì§€ broadlyí•œ ë²”ìœ„ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤
  
  ì¶”ê°€ë¡œ, Continual graph learning. , Lifelong learning Cross-domain Recommender Systems. Towards Out-of-Distiribution Generalization on Graphs. íŠœí† ë¦¬ì–¼ê¹Œì§€
  
  **ì‹œì¦Œí•œì •ë©”ë‰´. BIG GRAPH DATA with PyG** [[https://towardsdatascience.com/building-efficient-custom-datasets-in-pytorch-2563b946fd9f](https://towardsdatascience.com/building-efficient-custom-datasets-in-pytorch-2563b946fd9f?ref=graphusergroup.com)]
  
  1. ë…¸ë“œì™€ ë…¸ë“œê°€ ì–´ë–»ê²Œ ì—°ê²°ë˜ì–´ìˆëŠ”ì§€ src, dst 2ê°€ì§€ ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ” edge csv íŒŒì¼
  2. ë…¸ë“œê°€ ì–´ë–¤ feature ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ node csv íŒŒì¼
  
  ê°„ë‹¨í•˜ì§€ë§Œ, ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ í•œêº¼ë²ˆì— ì˜¬ë¦¬ë ¤ê³  ì‹œë„í•˜ì‹¤ë•Œ OOM ì˜¤ë¥˜ì™€ ë§Œë‚˜ê²Œ ë©ë‹ˆë‹¤.
  
  ì´ì „ load csv ì—ì„œëŠ” load í•´ì£¼ê³  Data í˜•íƒœë¡œ ë°”ê¿”ì£¼ëŠ” ê³¼ì •ì—ì„œ OOMì´ ë°œìƒí•˜ëŠ”ë°ìš”. ê·¸ ê³¼ì •ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì§„í–‰í•˜ê¸° ìœ„í•´ InMemoryDatasetë°©ì‹ì„ í™œìš©í•©ë‹ˆë‹¤.
  
  - customized datasetì´ ì´í•´ê°€ ì˜ ì•ˆëœë‹¤ ì‹¶ìœ¼ì‹œë©´ ì´ ë¸”ë¡œê·¸ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. íŠ¹íˆ Dataset, Dataloader ì´ ë­ê°€ ë‹¤ë¥´ë©°, ë¬´ìŠ¨ ìš”ì†Œë•Œë¬¸ì— memory efficientê°€ ë˜ëŠ”ì§€ ìœ ë…í•˜ì‹œë©´ì„œ ë³´ì‹œëŠ” ê±¸ ì¶”ì²œ

  <br>
    
</div>
</details>

<details>
<summary><b>23ë…„ 2ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">
    
  static and dynamic robustness Dynamic í¸
  
  **NodeAug: Semi-Supervised Node Classification with Data Augmentation** [[https://dl.acm.org/doi/abs/10.1145/3394486.3403063](https://dl.acm.org/doi/abs/10.1145/3394486.3403063?ref=graphusergroup.com)]
  
  ê·¸ë˜í”„ì—ì„œì˜ ë°ì´í„° ì¦ê°•
  
  - node attributeì™€ graph structureë¥¼ ë³€í˜•í•´ì£¼ë©° graph augmentation ì§„í–‰
  - subgraph mini-batch trainingì„ í†µí•´ large graphì—ì„œ ì–´ë–¤ ì‹ìœ¼ë¡œ trainingí•˜ë©´ ì¢‹ì„ì§€ì— ëŒ€í•œ ì´ì•¼ê¸°
  - ëª¨ë“  data agumentation ì´ ë§ŒëŠ¥ì´ ì•„ë‹ˆë¼ëŠ” ê´€ì ì„ ê²¬ì§€í•˜ì‹œê³  ë³´ì‹œë©´ ì¬ë°ŒëŠ” ì•„ì´ë””ì–´ê¹Œì§€ ì´ì–´ì§ˆ ê²ƒ ê°™ìŠµë‹ˆë‹¤ ğŸ™‚
  
  **ByteGraph: A Graph Database for TikTok**
  
  [[https://www.mydistributed.systems/2023/01/bytegraph-graph-database-for-tiktok.html?m=1](https://www.mydistributed.systems/2023/01/bytegraph-graph-database-for-tiktok.html?m=1&ref=graphusergroup.com)]
  
  ë§ì€ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì§ì ‘ ë§Œë“  ë°ì´í„°ë² ì´ìŠ¤ ì†Œê°œ **(ByteGraph)**
  
  - Low latency, high scalability ë‘ ì¡°ê±´ë“¤ì„ ë§Œì¡±í•˜ê¸° ìœ„í•´ 1. Edge-tree 2. Adaptive optimization 3. geographic replication ìš”ì†Œë“¤ì„ ì¤‘ì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„
  - Production ë ˆë²¨ì—ì„œ ì¤‘ìš”í•œ high scalablilty , low latency ìš”ì†Œë¥¼ ì–´ë–»ê²Œ ì„¤ê³„í•˜ëŠ”ì§€ ê¶ê¸ˆí•˜ì…¨ë˜ ë¶„ë“¤ì—ê²Œ ìœ ìš©í•œ ë ˆí¼ëŸ°ìŠ¤
  
  **NFT Wash Trading in the Ethereum Blockchain** [[https://arxiv.org/pdf/2212.01225.pdf](https://arxiv.org/pdf/2212.01225.pdf?ref=graphusergroup.com)]
  
  ìœ ì € ê°„ ë‹´í•©ì„ í†µí•´ NFTì˜ ê°€ê²©ì„ ìƒìŠ¹ì‹œí‚¤ëŠ” í–‰ìœ„ê°€ ì£¼ë¡œ ì–´ë–¤ ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ì— ëŒ€í•´ ë‹¤ë£¬ ë…¼ë¬¸
  
  - ë³µì¡ê³„ ë„¤íŠ¸ì›Œí¬ ì§€ì‹ í™œìš©ë¨
  - overviewë¥¼ ì˜ ê¸°ìˆ í•œ ë…¼ë¬¸
  
  **ZeRO: Memory Optimizations Toward Training Trillion Parameter Models** [[https://arxiv.org/pdf/1910.02054.pdf](https://arxiv.org/pdf/1910.02054.pdf?ref=graphusergroup.com)]
  
  parallelismì— ëŒ€í•´ ë…¼ì˜í•˜ë©° ê³¼ì—° data parallelismì´ model trainingì— ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤„ ê²ƒì¸ê°€ì— ëŒ€í•´ ë…¼ì˜í•˜ëŠ” ë…¼ë¬¸
  
  - Pipeline parallelism , Model parallelism , Cpu offloading ë“± ì „ë¬¸ê°€ë“¤ì˜ ë‹¤ì–‘í•œ ì‹¤í—˜ê³¼ í•´ì„ë“¤ì´ ì´ ì§‘í•©
  
  **big graph with ëª¨ë¸**
  
  ëª¨ë¸ì„ í†µí•´ big graph ë¥¼ ë‹¤ë£¨ëŠ” ë°©ì‹
  
  **Recent Advances in Efficient and Scalable Graph Neural Networks** [[https://www.chaitjo.com/post/efficient-gnns/#scalable-and-resource-efficient-gnn-architectures](https://www.chaitjo.com/post/efficient-gnns/?ref=graphusergroup.com#scalable-and-resource-efficient-gnn-architectures)]
  
  feature aggregation ì—ì„œ ê³¼ë„í•œ memory overhead ê°€ ë°œìƒí•˜ë¯€ë¡œ ê·¸ê²ƒë“¤ì„ pre-computation í•´ì„œ MLP (linear-layer) ì— íƒœìš°ë©´ light í•˜ë‹¤ ë¼ëŠ” ë§¥ë½
  
  - GNN ML ì—”ì§€ë‹ˆì–´ê°€ ëª©í‘œë¼ë©´ í•„ë… í•´ì•¼í•  ë¸”ë¡œê·¸
      - ë‹¤ì–‘í•œ ì—”ì§€ë‹ˆì–´ë§ ìŠ¤í‚¬ ê·¸ë¦¬ê³  practical ê·¸ë˜í”„ ì„ë² ë”© ë…¼ë¬¸ë“¤ ìˆ˜ë¡

  <br>
    
</div>
</details>
    
<details>
<summary><b>23ë…„ 2ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">    
    
  **Unleashing ML Innovation at Spotify with Ray** [[https://engineering.atspotify.com/2023/02/unleashing-ml-innovation-at-spotify-with-ray/](https://engineering.atspotify.com/2023/02/unleashing-ml-innovation-at-spotify-with-ray/?ref=graphusergroup.com)]
  
  Graph learning ì„ recommendation system ì— ì–´ë–»ê²Œ ì ìš©í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ê³  ê³„ì…¨ì„ ë¶„ë“¤ì—ê²Œ ë„ì›€ì´ ë˜ê² ë„¤ìš”. RAY + PyG ì˜ í˜•íƒœë¡œ í™œìš©ë©ë‹ˆë‹¤.
  
  - Production levelì—ì„œ GNNì´ í™œìš©ë˜ê¸° ì–´ë ¤ìš¸ê±°ë¼ ìƒê°í–ˆë˜ ì´ìœ ë“¤ì¸ subgraph sampling, batch trainingì´ Rayë¥¼ í†µí•´ í•´ê²°í•´ì„œ ì‹¤ì œ ë°°í¬ê¹Œì§€ ëœë‹¤ëŠ” ì‚¬ì‹¤
  
  **Search behavior prediction: A hypergraph perspective** [[https://www.amazon.science/publications/search-behavior-prediction-a-hypergraph-perspective](https://www.amazon.science/publications/search-behavior-prediction-a-hypergraph-perspective?ref=graphusergroup.com)]
  
  bipartite graph: ê³ ê°ì´ ì‡¼í•‘ì„ í•˜ë©° ë¬´ìŠ¨ í–‰ë™ì„ í•˜ëŠ”ì§€ í‘œí˜„í•  ë•Œ íš¨ê³¼ì ì¸ êµ¬ì¡°
  
  - Disassortative, Long-Tail Distribution ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì ì‹œë„
  - ì¶”ì²œì‹œìŠ¤í…œì—ì„œ hypergraphë¥¼ ë„ì…í•˜ëŠ” ì¶”ì„¸
  
  **Kumo - why graph is advantage in FDS industry** [[https://kumo.ai/ns-newsarticle-using-graph-learning-to-combat-fraud-and-abuse](https://kumo.ai/ns-newsarticle-using-graph-learning-to-combat-fraud-and-abuse?ref=graphusergroup.com)]
  
  Kumo, FDSì—ì„œ ì™œ Graphê°€ ì ì ˆí•œì§€ì— ëŒ€í•´ ì´ì•¼ê¸°
  
  - Rule based â†’ traditiaonl ML â†’ Graph ê¹Œì§€ ê¸°ìˆ ì´ ì˜ ë˜ì–´ìˆìŠµë‹ˆë‹¤.
  
  **T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation** [[https://arxiv.org/pdf/2212.12738.pdf](https://arxiv.org/pdf/2212.12738.pdf?ref=graphusergroup.com)]
  
  ê²½ëŸ‰í™” ì—”ì§€ë‹ˆì–´ë§ ìŠ¤í‚¬ ì¤‘ Knowledge distillationë¥¼ GNNì— ì–´ë–»ê²Œ ëŒ€ì…í•˜ëŠ”ì§€ì— ëŒ€í•´ ì´ì•¼ê¸°
  
  - knowledge distillation taskì—ì„œëŠ” node featureë¥¼ ì˜ ë‚˜íƒ€ë‚´ëŠ”ê²Œ ì¤‘ìš”í•˜ë‹¤ë¼ëŠ” ì‚¬ì‹¤ì„ ì‹¤í—˜ ê²°ê³¼ë¥¼ ê·¼ê±°ë¡œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  
  **Complex systems in the spotlight: next steps after the 2021 Nobel Prize in Physics** [[https://iopscience.iop.org/article/10.1088/2632-072X/ac7f75/pdf](https://iopscience.iop.org/article/10.1088/2632-072X/ac7f75/pdf?ref=graphusergroup.com)]
  
  ì¬ë¯¸ë¡œ ë³´ì‹œë©´ ì¢‹ì„ê±° ê°™ë„¤ìš”. ë³µì¡ê³„ ë„¤íŠ¸ì›Œí¬ì˜ next step ì— ëŒ€í•´ ë¬¼ë¦¬í•™ê³„ì—ì„œ ì €ëª…í•œ ë¶„ë“¤ì´ ì–¸ê¸‰í•˜ì‹  ë‚´ìš©ì…ë‹ˆë‹¤.
  
  - í–¥í›„ í•™ê³„ê°€ ì–´ë–¤ì‹ìœ¼ë¡œ í˜ëŸ¬ê°ˆì§€ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” íŒíŠ¸ë“¤ì´ ë§ˆêµ¬ë§ˆêµ¬ ì í˜€ìˆê¸°ì—, ì—°êµ¬ ë°©í–¥ì„±ì„ ì¡ìœ¼ì‹¤ ë•Œ ìœ ìš©í•˜ì‹¤ê±°ë¼ ìƒê°ë˜ë„¤ìš”.
  
  **Big graph with ë¦¬ì†ŒìŠ¤**
  
  **Quiver** [[https://github.com/quiver-team/torch-quiver](https://github.com/quiver-team/torch-quiver?ref=graphusergroup.com)] [[https://www-fourier.ujf-grenoble.fr/~mbrion/notes_quivers_rev.pdf](https://www-fourier.ujf-grenoble.fr/~mbrion/notes_quivers_rev.pdf?ref=graphusergroup.com)]
  
  PyG base performance ë¥¼ ëŒ€í­ í–¥ìƒì‹œí‚¨ í”„ë¡œì íŠ¸
  
  - 1. GPU accelerated(NVIDIA ë„¤íŠ¸ì›Œí¬ í†µì‹  ìµœì í™”) 2. torch-Quiver ë§Œì˜ ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¡° 3. íš¨ìœ¨ì ì¸ aggregation ì„ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ 4. ìµœì í™”ëœ ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ ë“±ì´ ê·¸ ì„±ëŠ¥ í–¥ìƒì˜ ë¹„ë²•
  
  **PyG-lib** [[https://pyg-lib.readthedocs.io/en/latest/modules/ops.html](https://pyg-lib.readthedocs.io/en/latest/modules/ops.html?ref=graphusergroup.com)]
  
  pyg-lib ì™€ torch-scatter, gather ì€ ëª¨ë‘ pip install ë¡œ ì„¤ì¹˜í•˜ë©´ ì ìš©ë˜ëŠ” low-level moduleì…ë‹ˆë‹¤. í—ˆë‚˜ pyg-libë¥¼ í™œìš©í•˜ê²Œ ëœë‹¤ë©´ ë”ìš± gpu ì¹œí™”ì ì¸ low-levelë¡œì¨ ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  
  **Memory-Efficient Aggregations** [[https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html](https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html?ref=graphusergroup.com)]
  
  dense-graph ë‚˜ large-graph ì—ì„œ gather-scatter ì€ ë¬¼ë¦¬ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê³µê°„ì„ ë§ì´ ì°¨ì§€í•©ë‹ˆë‹¤. ì´ë¥¼ sparse-tensor[[https://arxiv.org/abs/1803.08601](https://arxiv.org/abs/1803.08601?ref=graphusergroup.com)] í™œìš©í•´ì„œ í•´ê²°í•©ë‹ˆë‹¤.
  
  **EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression** 
  
  [[https://openreview.net/forum?id=vkaMaq95_rX](https://openreview.net/forum?id=vkaMaq95_rX&ref=graphusergroup.com)] [code:Â [https://github.com/warai-0toko/Exact](https://github.com/warai-0toko/Exact?ref=graphusergroup.com)]
  
  Quantizedë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì••ì¶•ì‹œì¼œì¤Œìœ¼ë¡œì„œ, ì„±ëŠ¥ ê°œì„ ì„ ì´ëŒì–´ëƒ…ë‹ˆë‹¤.

  <br>
    
</div>
</details>
    
<details>
<summary><b>23ë…„ 2ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">     
    
  **Graph Neural Networks Go Forward-Forward modeling** [[https://arxiv.org/pdf/2302.05282.pdf](https://arxiv.org/pdf/2302.05282.pdf?ref=graphusergroup.com)]
  
  â€˜Backward ë¥¼ Forward ë¡œ ëŒ€ì²´í•œë‹¤â€™ë¼ëŠ” ì°¸ì‹ í•œ ì•„ì´ë””ì–´ë¥¼ ì ìš©í•œ ë…¼ë¬¸
  
  - ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬: 1. label encoding 2. Goodness function of a graph 3. Inference without backprop
  - large , big ê°™ì€ ëŒ€ìš©ëŸ‰ í•™ìŠµ íŠ¸ë Œë“œì—ì„œ ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•  ìˆ˜ ìˆëŠ” ë…¼ë¬¸
  
  **On the Connection Between MPNN and Graph Transformer** [[https://arxiv.org/abs/2301.11956](https://arxiv.org/abs/2301.11956?ref=graphusergroup.com)]
  
  Why graph transformer? ë¼ëŠ” ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ í…Œí¬ë‹‰ë“¤ì´ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤. ë”ë¶ˆì–´, Graph Transformer ê´€ì ë“¤ì„ ì ìš©í•œ GPS , Graphhormer ë“± sota ë“¤ê³¼ ë¹„êµí•œ ë¶€ë¶„ì´ í¥ë¯¸ë¡­ìŠµë‹ˆë‹¤.
  
  - graph transformer ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¼ë¬¸ì„ ì‘ì„±í•˜ê³  ì‹¶ìœ¼ì‹œê±°ë‚˜ , ì™œ Transformer ì—ì„œ positional encoding , self attention ê°€ ì¤‘ìš”í•œì§€ ê¶ê¸ˆí•˜ê±°ë‚˜ ìˆ˜í•™ì ìœ¼ë¡œ ìŒë¯¸í•˜ê³  ì‹¶ìœ¼ì‹  ë¶„ë“¤ê»˜ì„œ ë³´ì‹œë©´ ì¢‹ì„ ë…¼ë¬¸
  
  **A GENERALIZATION OF VIT/MLP-MIXER TO GRAPHS** [[https://arxiv.org/pdf/2212.13350.pdf](https://arxiv.org/pdf/2212.13350.pdf?ref=graphusergroup.com)]
  
  graph ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•˜ê²Œ ìƒê°ë˜ëŠ” over-squashing , long-range dependency ë‘ê°€ì§€ ë¬¸ì œë¥¼ MLP mixer ê¸°ìˆ ë¡œ í•´ê²°í•´ë³´ê³ ì ì‹œë„
  
  - ì—¬ëŸ¬ëª¨ë¡œ ê¸°ë°œí•œ ê¸°ìˆ ë“¤ì´ ë§ì´ ë“¤ì–´ê°„ ë…¼ë¬¸
  
  **An Introduction to Topological Data Analysis: Fundamental and Practical Aspects for Data Scientists** [[https://www.frontiersin.org/articles/10.3389/frai.2021.667963/full](https://www.frontiersin.org/articles/10.3389/frai.2021.667963/full?ref=graphusergroup.com)]
  
  ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì„ í†µí•´ topologyë¥¼ í•´ì„í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ ìœ„ìƒ ìˆ˜í•™ topology analysisë¥¼ í†µí•´ topologyë¥¼ ì–´ë–»ê²Œ ì ‘ê·¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ìë£Œ
  
  - ì•„ë§ˆë„ 3D + graphë¥¼ ê³µë¶€í•˜ì‹œëŠ” ë¶„ë“¤ì—ê²Œ ë§ì€ ë„ì›€

  <br>
    
</div>
</details>

<details>
<summary><b>23ë…„ 2ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">
    
  **Breaking the Limit of Graph Neural Networks by Improving the Assortativity of Graphs with Local Mixing Patterns** [[https://arxiv.org/pdf/2106.06586.pdf](https://arxiv.org/pdf/2106.06586.pdf?ref=graphusergroup.com)]
  
  ë™ì§ˆì„±(Assortativity)
  
  - data-centric ê´€ì ì—ì„œ ì˜ í’€ì–´ ë†“ì€ ë…¼ë¬¸ì…ë‹ˆë‹¤. ë‹¤ ì½ì–´ë³´ê³  ë‚˜ì‹œë©´ graph embedding modelì´ ì•„ë‹Œ graph pattern, graph distribution ê·¸ë¦¬ê³  graph modelingì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ì— ëŒ€í•´ ì²´ê°í•˜ì‹œê²Œ ë  ê±°ë¼ ìƒê°ë©ë‹ˆë‹¤.
  - GNN vs. local assortativityë¼ëŠ” ì„¹ì…˜ì—ì„œ ëª¨ë¸ vs. ë°ì´í„° ê´€ì ì—ì„œ ì ‘ê·¼í•œ êµ‰ì¥íˆ í¥ë¯¸ë¡œìš´ ë¶€ë¶„ë„ ì¡´ì¬
  - GNNë„ ì¢‹ì§€ë§Œ, í•™ìŠµí•˜ëŠ” ë°ì´í„°ì— ëŒ€í•œ ì¤‘ìš”ì„± garbage in, garbage outì„ ë‹¤ì‹œ í•œ ë²ˆ ê¹¨ë‹«ê²Œ í•˜ëŠ” ë…¼ë¬¸
  
  **GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks** [[https://arxiv.org/pdf/2302.08043.pdf](https://arxiv.org/pdf/2302.08043.pdf?ref=graphusergroup.com)]
  
  chatGPT ë¶ìœ¼ë¡œ ì¸í•´ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ ì´ì „ ëŒ€ë¹„ êµ‰ì¥í•œ ê´€ì‹¬ì„ ë°›ê³  ìˆëŠ” ì¶”ì„¸ì¸ ê°€ìš´ë° ê·¸ë˜í”„ ë¶„ì•¼ì—ì„œë„ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ìŠ¤í‚¬ì„ ì ìš©í•œ ë…¼ë¬¸ì´ ë“±ì¥
  
  - Pre-training weightë¥¼ í™œìš©í•˜ê¸° ìœ„í•œ ìŠ¤í‚¬ì¸ fine-tuning ì´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” ì˜ ì‘ë™í•˜ë‚˜, ê·¸ë˜í”„ ë¶„ì•¼ì—ì„œëŠ” ë§Œì¡±í• ë§Œí•œ ì„±ëŠ¥ì„ ì´ëŒì–´ë‚´ì§€ ëª»í–ˆìŒì„ í•œê³„ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ë©° prompt ì»¨ì…‰ì„ ì œì‹œ
  - ê·¸ë˜í”„ ë¶„ì•¼ì—ì„œ pretraining ì´ë€ MPNN ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ë…¸ë“œ ë§í¬ ê·¸ë˜í”„ 3ê°€ì§€ ë°©ì‹ì„ ëª¨ë‘ í•™ìŠµí•´ì£¼ëŠ” ë°©ì‹ì´ ì •ì„ì²˜ëŸ¼ ì—¬ê²¨ì§€ê³¤ í–ˆì—ˆëŠ”ë°ìš”. ì—¬ê¸°ì—ì„œë„ ë…¸ë“œ ë§í¬ ê·¸ë˜í”„ structure wise ë¼ëŠ” ê´€ì ì„ ë™ì¼í•˜ë‚˜, pattern specific ì„ ìœ„í•´ vector similarity ë¥¼ í™œìš©í•œ ì•„ì´ë””ì–´ê°€ ì°¸ì‹ í•˜ë‹¤ê³  ìƒê°ë˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.
  
  **Simplifying Subgraph Representation Learning for Scalable Link Prediction** [[https://arxiv.org/pdf/2301.12562.pdf](https://arxiv.org/pdf/2301.12562.pdf?ref=graphusergroup.com)]
  
  ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì—ì„œ ë°œìƒí•˜ëŠ” í™•ì¥ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì„œë¸Œê·¸ë˜í”„ ë° í™•ì‚° ì—°ì‚°ìë¥¼ í™œìš©
  
  - ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œì„ í†µí•´ ì˜ˆì¸¡í•  ë§í¬ê°€ ì„œë¸Œê·¸ë˜í”„ì— ì¡´ì¬í•˜ëŠ”ì§€, ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ì§€ ê·¸ë¦¬ê³  ì¡´ì¬í•œë‹¤ë©´ ê·¼ì²˜ k-hopê³¼ êµë¥˜(diffusion)ê°€ ë°œìƒí•  ë•Œ, ì„ë² ë”© ê°’ì´ ì–´ë–»ê²Œ ë³€í™”ë˜ëŠ”ì§€ë¥¼ ì¤‘ì ì ìœ¼ë¡œ í™•ì¸
  - ë©”ì‹œì§€ íŒ¨ì‹±ì„ í™•ì‚° ì—°ì‚°ìë¡œ ëŒ€ì²´í•œë‹¤ëŠ” ê´€ì ì—ì„œ ë§¤ìš° í¥ë¯¸ë¡œì› ë˜ ë…¼ë¬¸
  - ë˜í•œ ìƒ˜í”Œë§ ì „ëµì—ì„œ PoS(power of subgraph)ì™€ SoP(subgraph of power)ë¥¼ ì–¸ê¸‰í•˜ë©° ê°ê°ì˜ ì°¨ì´ì™€ ì¥ë‹¨ì ì— ëŒ€í•´ ì–¸ê¸‰í•œ ë¶€ë¶„ë„ í¥ë¯¸ë¡œì› ìŠµë‹ˆë‹¤.
  
  **LINE: Large-scale Information Network Embedding** [[https://arxiv.org/pdf/1503.03578.pdf](https://arxiv.org/pdf/1503.03578.pdf?ref=graphusergroup.com)]
  
  ëŒ€í‘œì ì¸ large-scale graph embedding ê¸°ìˆ ì¸ LINEì€ ë„¤íŠ¸ì›Œí¬ ë‚´ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ” ë…¸ë“œë¿ë§Œ ì•„ë‹ˆë¼, ê³µí†µ ì´ì›ƒì„ ê°€ì§€ê³  ìˆëŠ” ê°„ì ‘ì—°ê²° ë…¸ë“œë“¤ì˜ êµ¬ì¡°ì  íŠ¹ì„±ì„ ëª¨ë‘ ì„ë² ë”©ì— ë‹´ê³ ì ì‹œë„í•œ ë…¼ë¬¸
  
  - First-orderì™€ second-orderë¼ëŠ” ë‹¨ì–´ë¥¼ í†µí•´ ê¸°ìˆ ë“¤ì„ ì„¤ëª…
  - second-orderì—ì„œ negative samplingì„ ì ìš©í•´ì„œ model optimizationê¹Œì§€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ëŠ”ì§€ë¥¼ ì‚´í´ë³´ëŠ” ê²ƒì´ í¥ë¯¸ë¡œìš¸ ê²ƒì…ë‹ˆë‹¤. optimizationì‹œì—ëŠ” asynchronous stochastic gradient algorithmì„ í™œìš©í•˜ëŠ”ë°, ì´ë•Œ continuous weight â†’ discrete weightë¡œ ì „í™˜í•˜ëŠ” ë°©ì‹ì´ êµ‰ì¥íˆ í¥ë¯¸ë¡­ìŠµë‹ˆë‹¤.

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 3ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  **Identifying critical nodes in complex networks by graph representation learning** [https://arxiv.org/pdf/2201.07988.pdf](https://arxiv.org/pdf/2201.07988.pdf?ref=graphusergroup.com)
  
  ë°©ëŒ€í•œ ë°ì´í„° ì†ì—ì„œ ì¤‘ìš”í•œ ë…¸ë“œë¥¼ ì°¾ê¸° ìœ„í•´ ì»·íŒ…(ìƒ˜í”Œë§)ê³¼ ê°™ì€ íœ´ë¦¬ìŠ¤í‹±ì ì¸ ë°©ì‹ ì ìš©í•˜ê³¤ í•¨
  
  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê·¸ë˜í”„ ì„ë² ë”© ë°©ì‹ê³¼ íœ´ë¦¬ìŠ¤í‹±ì„ ì¡°í•©í•œ ë°©ì‹ì„ í†µí•´ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ì—ì„œ ì¤‘ìš”í•œ ë…¸ë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì•„ì´ë””ì–´ë¥¼ ì œì‹œ: **influence maximization**
  
  - network critical node identifiy ë¥¼ ìœ„í•´ ë³µì¡ê³„ ë„¤íŠ¸ì›Œí¬ ì—°êµ¬ìë“¤ì´ ì–´ë–¤ ë°©ì‹ì„ ì ìš©í–ˆì—ˆëŠ”ì§€ì— ëŒ€í•œ íˆìŠ¤í† ë¦¬ë“¤ì´ ì˜ ì •ë¦¬ë˜ì–´ìˆì–´ì„œ ëª°ëì—ˆë˜ ì§€ì‹ì„ ì¶©ì „í•˜ëŠ” ëŠë‚Œì´ë¼ êµ‰ì¥íˆ í¥ë¯¸ë¡œì› ì—ˆë˜ ë…¼ë¬¸
  - VoteRank, EnRenew, Improved Kshell and NCVoteRank ë¼ëŠ” methodology ë“¤ì— ëŒ€í•´ ì•Œê²Œë˜ì–´ í•œ ì¸µ ì„±ì¥í•œ ëŠë‚Œ
  
  **LINK PREDICTION WITH NON-CONTRASTIVE LEARNING** [[https://arxiv.org/abs/2211.14394](https://arxiv.org/abs/2211.14394?ref=graphusergroup.com)]
  
  contrastive-learning , positive sample ê³¼ negative sampleë¥¼ ì¡°í•©í•´ì„œ ì„ë² ë”©ì„ ë” ì˜í•´ë³´ë ¤ëŠ” ë°©ì‹
  
  - Link prediction íŠ¹íˆ recommender system ì—ì„œ ë§ì´ í™œìš©ë˜ê³  ìˆëŠ” ë°©ì‹
  - ì €ìëŠ” ì´ ë°©ì‹ì— 1. Negative sampling cost 2. Overfitting ë¬¸ì œê°€ ìˆë‹¤ê³  ì£¼ì¥. ì €ìëŠ” non-contrastive learning ë°©ì‹ì„ í™œìš©.
  
  Simple corrpution function ì„ í†µí•´ negative sampling ì§„í–‰í•˜ì—¬ expensive cost ë¥¼ cheap costë¡œ ì „í™˜í•˜ë ¤ëŠ” ì•„ì´ë””ì–´ë¥¼ ì œì•ˆ
  
  - Cold-start problem , graph SSL ë“±ì´ í™”ë‘ê°€ ë˜ë©° contrastive learning ì˜ ê´€ì‹¬ì´ ë¶€ì© ì˜¬ë¼ê°€ê³  ìˆëŠ” ì¶”ì„¸
  
  **Global Context Enhanced Graph Neural Networks for Session-based Recommendation** [[https://arxiv.org/pdf/2106.05081.pdf](https://arxiv.org/pdf/2106.05081.pdf?ref=graphusergroup.com)]
  
  ë…¼ë¬¸ í•µì‹¬: â€œsession ë§ˆë‹¤ contextê°€ ë°œìƒí•  í…ë° ì´ë¥¼ globalê³¼ sessionìœ¼ë¡œ êµ¬ë¶„ì§€ì–´ ì„ë² ë”©í•œë‹¤.â€
  
  global graphê°€ ê²°êµ­ ìƒˆë¡œìš´ ê´€ì ì´ì, ë…¼ë¬¸ì˜ ì£¼ ì•„ì´ë””ì–´
  
  - global graphë¥¼ ë§Œë“œëŠ” ë°©ì‹
  - ì¶”ì²œì‹œìŠ¤í…œì—ì„œ ì™œ ìœ ì €ì˜ ì „í›„ë§¥ë½ì´ ì¤‘ìš”í• ê¹Œ?ë¼ëŠ” ì˜ë¬¸ì„ ê°€ì§€ë©´ì„œ ë³´ì‹œë©´ ì¢‹ì„ ë…¼ë¬¸
  
  **LT-OCF: Learnable-Time ODE-based Collaborative Filtering** [[https://arxiv.org/pdf/2108.06208.pdf](https://arxiv.org/pdf/2108.06208.pdf?ref=graphusergroup.com)]
  
  ë¯¸ë¶„ ë°©ì •ì‹ê³¼ graph smoothnessì˜ ì¡°í•©ì´ ì™œ í˜‘ì—… í•„í„°ë§(CF)ì—ì„œ ìœ ì˜ë¯¸í•œì§€ì— ëŒ€í•´ ì´ì•¼ê¸°
  
  ë³¸ ë…¼ë¬¸ì˜ ì¥ì  ë‘ ê°€ì§€
  
  1. ë¯¸ë¶„ë°©ì •ì‹ì„ í™œìš©í•´ parameterë¥¼ ë§ì´ ì¤„ì˜€ë‹¤.
  2. discrete í˜•ì‹ì˜ time valueë¥¼ continousí•˜ê²Œ ë³€í˜•í•˜ì—¬ í™œìš©í•œë‹¤.
  - ìˆ˜í•™ì  í…Œí¬ë‹‰ê³¼ ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ì¶”ì²œì‹œìŠ¤í…œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ë¶„ë“¤ê»˜ì„œ ë³´ì‹œë©´ ì¢‹ì„ ë…¼ë¬¸
  
  **Hardyê°€ k8s ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ì´ìœ **
  
  MLops with graph machine learning ìœ¼ë¡œë¶€í„° k8sì— ëŒ€í•´ ê´€ì‹¬

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 3ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  **Graph Rewiring: From Theory to Applications in Fairness** [https://github.com/ellisalicante/GraphRewiring-Tutorial](https://github.com/ellisalicante/GraphRewiring-Tutorial?ref=graphusergroup.com)
      
  GNN ê³ ì§ˆì ì¸ ë¬¸ì œì¸ â€˜over-smoothing , over-squashing and under-reaching ì„ ì–´ë–»ê²Œ ë„¤íŠ¸ì›Œí¬ ì´ë¡ ìœ¼ë¡œ í•´ê²°í•´ë³¼ê²ƒì¸ê°€â€™ë¼ëŠ” ê´€ì ì´ ë‹´ê²¨ìˆëŠ” íŠœí† ë¦¬ì–¼

  - í•´ë‹¹ graph rewiring functionë“¤ì„ ì–´ë–¤ì‹ìœ¼ë¡œ êµ¬ì„±í• ì§€ì— ëŒ€í•´ ê¸°ì´ˆì§€ì‹(spectral theroy) ë¶€í„° transductive, inductive sampling ê´€ì ìœ¼ë¡œ ì ‘ê·¼
  - graph fairnessê¹Œì§€ ì´ë¡ ë¶€í„° ì‹¤ë¬´ì ìš© ê´€ì ê¹Œì§€ ì˜¬ì¸ì›ìœ¼ë¡œ ë‹¤ë£¬ íŠœí† ë¦¬ì–¼

  **On Generalized Degree Fairness in Graph Neural Networks** [https://arxiv.org/pdf/2302.03881.pdf](https://arxiv.org/pdf/2302.03881.pdf?ref=graphusergroup.com)

  GNNëŠ” degreeì— ë”°ë¼ ì •ë³´ì˜ ì „ë‹¬ëŸ‰ì´ ë‹¬ë¼ì§€ê³  ê·¸ ì •ë³´ì˜ ì „ë‹¬ì— ë”°ë¼ nodeì˜ smoothnessê°€ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ì–´ë–»ê²Œ ì ì ˆíˆ ë°°ë¶„í•˜ëŠ”ì§€ê°€ ì¤‘ìš”

  ì—¬ê¸°ì—ì„œëŠ” degree fairness ê´€ì ìœ¼ë¡œ ì ‘ê·¼

  **Learning Stance Embeddings from Signed Social Graphs** [https://arxiv.org/pdf/2201.11675.pdf](https://arxiv.org/pdf/2201.11675.pdf?ref=graphusergroup.com)

  singed network: ë…¸ë“œê°„ì˜ ê´€ê³„ì˜ ê¸/ë¶€ì •ì„ ì§ì ‘ ëª…ì‹œí•˜ê¸° ìœ„í•œ ê·¸ë˜í”„

  'singed network'ì—ì„œ ê¸ì •/ë¶€ì • ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ ë„˜ì–´ì„œ, ê° íŠ¸ìœ—ì´ ì–´ë–¤ ì£¼ì œì— ëŒ€í•œ ê¸ì •/ë¶€ì •ì„ í¬í•¨í•˜ëŠ”ì§€ë¥¼ ê³ ë ¤í•˜ì—¬ ì„ë² ë”©í•˜ëŠ” ë°©ë²• ì œì•ˆ

  - ê·¸ë˜í”„ ê¸°ìˆ ì˜ ê¸°ì´ˆì¸ random-walk ì™€ societal practical perceptive ê°€ ì˜ ì–´ìš¸ëŸ¬ì§„ ë…¼ë¬¸
  - ì–´ë–»ê²Œ ì†Œì…œê´€ì ê³¼ ê·¸ë˜í”„ê´€ì ì„ ì˜ ì ‘ëª©í–ˆëŠ”ì§€ì— ëŒ€í•œ í˜¸ê¸°ì‹¬ì„ ê¸°ë°˜ìœ¼ë¡œ ë³´ì‹œë©´ êµ‰ì¥íˆ ì¬ë°Œì„ ë…¼ë¬¸
  - ì‚¬íšŒê³¼í•™ìª½ì—ì„œ ê·¸ë˜í”„ë¥¼ í™œìš©í•˜ì‹¤ ë¶„ë“¤ê»˜ ì¶”ì²œ

  **DemoMotif: Demographic Inference from Sparse Records of Shopping Transactions based on Motif Patterns**

  ê³ ê°ë“¤ì˜ ì˜ìˆ˜ì¦ê³¼ ê°™ì€ ì¼ë ¨ì˜ êµ¬ë§¤ í–‰ìœ„ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ê°ì˜ ì¸êµ¬í†µê³„í•™ì ì •ë³´ë¥¼ ìœ ì¶”í•˜ëŠ” ë…¼ë¬¸

  - ë³¸ ë°©ë²•ë¡ ì€ í–‰ìœ„ë“¤ì„ heterogeneous graph motifë¡œ êµ¬ì„±í•˜ì—¬ motif íŒ¨í„´ ì„ë² ë”© ìµœì í™”ì— ì´ˆì 
  - ê¸°ì¡´ì—ëŠ” ëª¨ë“  ì •ë³´ë“¤ì„ ì‹¬í”Œí•˜ê²Œ ë…¸ë“œì˜ featureë¡œ ë‹´ì•„ì„œ parameter updateí•˜ëŠ” ë§¥ë½ì´ì˜€ë‹¤ë©´, ì´ë¥¼ í–‰ìœ„ ë…¸ë“œë¡œ ê°„ì£¼í•˜ì—¬ ê·¸ë˜í”„ë¡œ ëª¨ë¸ë§ í•œ í›„ motif embedding í•˜ëŠ” ë§¥ë½
  - ê·¸ë˜í”„ ëª¨ë¸ë§ì— íœ´ë¦¬ìŠ¤í‹±ì´ ë“¤ì–´ê°€ê² ìœ¼ë‚˜ ëª©ì ì— ê±¸ë§ê²Œ ë””ìì¸í•œë‹¤ë©´ ê·¸ í•¸ë””ìº¡ì€ ì¶©ë¶„íˆ ê°ì•ˆí•  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ ë¼ê³  ì‹œì•¼ë¥¼ ë„“í˜€ì¤€ ì¢‹ì€ ë…¼ë¬¸

  **Some Techniques To Make Your PyTorch Models Train (Much) Faster** [https://sebastianraschka.com/blog/2023/pytorch-faster.html](https://sebastianraschka.com/blog/2023/pytorch-faster.html?ref=graphusergroup.com)
  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 3ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  **Weighted flow diffusion for local graph clustering with node attributes: an algorithm and statistical guarantees** [[https://arxiv.org/pdf/2301.13187.pdf](https://arxiv.org/pdf/2301.13187.pdf?ref=graphusergroup.com)]
    
  attribute í™œìš©í•˜ê¸° ìœ„í•´ flow diffusion model ì°¨ìš©
  
  - ë…¸ë“œê°„ ì „ë‹¬ë˜ëŠ” loadë¥¼ weighted graph í˜•íƒœë¡œ ì ìš©í•˜ë©°, ë…¸ë“œê°„ proximity ë°˜ì˜
  - â€¢ graph clustering ë°©ë²•ë¡ ë“¤ì€ ë…¸ë“œ , ì—£ì§€ì˜ êµ¬ì¡°ë§Œì„ í™œìš©í•œ ë°©ì‹ë“¤ì´ ëŒ€ë‹¤ìˆ˜ì…ë‹ˆë‹¤. large graph ì—ì„œ conductance ë¼ëŠ” ì„œë¸Œ ê·¸ë˜í”„ê°„ tightly connected ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œë¥¼ í† ëŒ€ë¡œ clustering ì´ ì˜ ë˜ì—ˆëŠ”ì§€ ë˜ì§€ ì•Šì•˜ëŠ”ì§€ë¥¼ íŒë‹¨í•˜ê³¤ í–ˆì£ . í•˜ì§€ë§Œ, ê·¸ë˜í”„ êµ¬ì¡° ì •ë³´ë§Œì„ ì–»ê³  , í™œìš©í•  ìˆ˜ ìˆì—ˆë˜ ì´ì „ê³¼ ë‹¤ë¥´ê²Œ í˜„ì¬ëŠ” node , edge attributes ê³¼ ê°™ì€ ì •ë³´ë˜í•œ ì–»ê³  í™œìš©í•  ìˆ˜ ìˆê¸°ì— ê·¸ë˜í”„ êµ¬ì¡°ë§Œì„ í† ëŒ€ë¡œ Clustering í•˜ëŠ” ê¸°ì¡´ ë°©ë²•ë¡ ë“¤ì€ old-fashioned í•œ ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.
  - clustering + attribute ë¥¼ diffusion operator ë„¤íŠ¸ì›Œí¬ ì´ë¡  ì¸¡ë©´ìœ¼ë¡œ ì ‘ê·¼í–ˆë‹¤ëŠ” ì¸¡ë©´ì—ì„œ êµ‰ì¥íˆ ì¬ë°Œì—ˆìŠµë‹ˆë‹¤. good attributes ê¸°ì¤€ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œë„ ì´ì•¼ê¸°ê°€ ë‚˜ì™€ìˆìœ¼ë‹ˆ, node feature engineering ì— ëŒ€í•œ ê³ ë¯¼ì´ ìˆìœ¼ì‹  ë¶„ë“¤ì—ê²Œ ë„ì›€
  
  **LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation** [[https://arxiv.org/pdf/2302.01503.pdf](https://arxiv.org/pdf/2302.01503.pdf?ref=graphusergroup.com)]
  
  spectral ê´€ì ì—ì„œ ë°œìƒí•˜ëŠ” Diffusion informationì„ íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ë£¸ìœ¼ë¡œì¨ ê·¸ë˜í”„ ì„ë² ë”©ì˜ ê³ ì§ˆì ì¸ ë¬¸ì œì¸ â€˜over-smoothingâ€™ í•´ê²°í•˜ëŠ” ë°©ì•ˆ ì œì‹œ
  
  - graph node ê°„ ë°œìƒí•˜ëŠ” load (message)ì˜ ê¸°ìš¸ê¸° ì •ë³´ë¥¼ ì´ˆê¸°í™” í•˜ì§€ ì•Šê³  ì¬í™œìš©í•˜ì—¬ layer ìˆ˜ë¥¼ ì¤„ì´ê³  ê·¸ì— ë”°ë¼ loadì—ì„œì˜ ìµœì ì˜ ì •ë³´ë§Œì„ í™œìš©
  
  ë…¼ë¬¸ì˜ í•µì‹¬: ê¸°ìš¸ê¸° ì •ë³´ì™€ ê·¸ë˜í”„ í™•ì‚° ì´ë¡ ì„ ê²°í•©í•œ ì•„ì´ë””ì–´
  
  - ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ì¸ ìˆœì „íŒŒì™€ ì—­ì „íŒŒì˜ íë¦„ì— ëŒ€í•œ ì´í•´ì™€ ê·¸ë˜í”„ ì •ë³´ ì´ë¡ ì— ì´í•´ê°€ ìˆëŠ” ë¶„ë“¤ì´ ì´ ë…¼ë¬¸ì„ ì‰½ê²Œ ë³¼ ìˆ˜ ìˆì„ ê²ƒ
  - ë˜í•œ ë©”ì‹œì§€ íŒ¨ì‹±ì—ì„œ íŒŒë¼ë¯¸í„°ê°€ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸ë˜ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ íŒŒë¼ë¯¸í„°ê°€ ì†ë„ì™€ ì •í™•ë„ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ê¶ê¸ˆí•´í•˜ì‹œëŠ” ë¶„ë“¤ì—ê²Œ ì´ ë…¼ë¬¸ì„ ì¶”ì²œ
  - í˜„ì—…ì—ì„œ GNNì„ í™œìš©í•˜ê³  ì‹¶ì§€ë§Œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ëª¨ë¸ë¡œ ì¸í•´ ê³ ë¯¼í•˜ëŠ” ë¶„ë“¤ì—ê²Œë„ ë„ì›€
  
  **Attending to Graph Transformers** [[https://arxiv.org/pdf/2302.04181.pdf](https://arxiv.org/pdf/2302.04181.pdf?ref=graphusergroup.com)]
  
  GT(Graph Transformer)ì˜ Encoding, input feature, tokenize, propagation 4ê°€ì§€ ìš”ì†Œë“¤ì— ë”°ë¼ ê° taskë“¤ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€ì— ëŒ€í•œ Research questionì„ answering
  
  globally, locally attentionì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— over-smoothingê³¼ over-squashing ë¬¸ì œì— ì§ë©´í•˜ê²Œ ë˜ëŠ”ë° ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€ì— ëŒ€í•œ ì‹¤í—˜ê³¼ ì‹¤í—˜ê²°ê³¼ì— ëŒ€í•œ í•´ì„
  
  - ë¨¸ì§€ì•Šì•„ Graph ë°ì´í„° ì—ì„œë„ Transformerì˜ ì‹œëŒ€ê°€ ì˜¤ì§€ì•Šì„ê¹Œ í•˜ëŠ” ìƒê°ì´ ë“œë„¤ìš”. Graph Transformer ëª¨ë¸ í™œìš©ì „, ì‹œí–‰ì°©ì˜¤ë¥¼ ì¤„ì´ê¸°ì— ì¢‹ì€ ì§€ì¹¨ì„œê°€ ë  ë…¼ë¬¸
  
  **Why (Graph) DBMSs Need New Join Algorithms: The Story of Worst-case Optimal Join Algorithms** [[https://kuzudb.com/blog/wcoj.html](https://kuzudb.com/blog/wcoj.html?ref=graphusergroup.com)]
  
  wcoj(worst-case optimal join algorithm) ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì„¤ëª…
  
  - ê·¸ë˜í”„ ë°ì´í„° ë² ì´ìŠ¤ íš¨ìœ¨ì„±ì€ ê²°êµ­ Join speed , large dataset handling ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°êµ­ ì‹¤ì‹œê°„ì„± ë°ì´í„°ê°€ ë§ì•„ì§€ëŠ” ìš”ì¦˜ ê·¸ ë°ì´í„°ë“¤ì„ ì–´ë–»ê²Œ ì˜ ì†Œí™”ì‹œí‚¤ëŠ”ì§€ê°€ í•µì‹¬ì¸ë°ìš”. ê·¸ íš¨ìœ¨ì„±ì˜ ê¸°ì¡°ê°€ ë˜ëŠ” ê¸°ìˆ ë“¤ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì…¨ë˜ ë¶„ë“¤ì—ê²Œ ì¢‹ì„ ìë£Œ
  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 3ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">

  **Social network analysis of Japanese manga: similarities to real-world social networks and trends over decades** [[https://arxiv.org/pdf/2303.07208.pdf](https://arxiv.org/pdf/2303.07208.pdf?ref=graphusergroup.com)]
    
  ì¼ë³¸ ë§Œí™”ì—ì„œ ë“±ì¥ì¸ë¬¼ê°„ì˜ ê´€ê³„ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„
  
  ë‘ ê°€ì§€ ê°€ì„¤ ê¸°ë°˜ ì ‘ê·¼
  
  1. 70ë…„ê°„ ë“±ì¥í•œ ë§Œí™” ìºë¦­í„°ë“¤ì„ ë¶„ì„í•´ì„œ ì§€ê¸ˆê³¼ ê·¸ë•Œì˜ íŠ¸ë Œë“œëŠ” ì‹œìŠ¤í…œì ìœ¼ë¡œ ë‹¤ë¥¼ ê²ƒì´ë©°,
  2. ì´ ë¶„í¬ë“¤ì€ real-social networkì™€ ë¹„ìŠ·í•  ê²ƒì´ë‹¤.
  
  ê²°ê³¼: ì¸ê°„ì˜ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì™€ ìœ ì‚¬í•˜ê²Œ ë§Œí™”ì˜ ë“±ì¥ì¸ë¬¼ë“¤ë„ ë‹¤ì–‘í•œ ì—°ê²° ê´€ê³„ ê°€ì§€ê³  ìˆë‹¤.
  
  - ë‹¤ì–‘í•œ í˜ì´ì§€ì— ë¶ˆê· í˜•ì ìœ¼ë¡œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ì†Œìˆ˜ì˜ ë“±ì¥ì¸ë¬¼ë“¤ì´ ë“±ì¥í•¨ìœ¼ë¡œì¨ ë„¤íŠ¸ì›Œí¬ë¥¼ ì´ëŒì–´ ê°„ë‹¤.
  - ì´ë¥¼ ë„¤íŠ¸ì›Œí¬ ì •ëŸ‰í™” ì§€í‘œ strength, average degree, bipartite â†’ one-mode network and analysis, assortativity ë“±ì„ í™œìš©í•˜ì—¬ ê·¸ ê²°ê³¼ë“¤ì„ í•´ì„
  
  SI ëª¨ë¸ì„ í™œìš©í•´ì„œ Inter-Event Time (IET) distribution ì„ ë¶„ì„í•˜ëŠ” ì„¹ì…˜ì´ í¥ë¯¸ë¡œì›€
  
  ì ‘ê·¼ ë°©ë²•ë¡ ì„ ë²¤ì¹˜ë§ˆí¬í•˜ì—¬ í˜„ì—…ì—ì„œ HRí•˜ì‹œëŠ” ë¶„ë“¤ì´ ì ìš©í•´ë³´ì‹œë©´ ì¬ë°ŒëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ ì•Šì„ê¹Œ
  
  **PyG 2.3.0** [[https://github.com/pyg-team/pytorch_geometric/releases/tag/2.3.0](https://github.com/pyg-team/pytorch_geometric/releases/tag/2.3.0?ref=graphusergroup.com)]
  
  PyG is a library built upon PyTorch to easily write and train Graph Neural Networks for a wide range of applications related to structured data.
  
  **Compiled Graph Neural Networks** [https://pytorch-geometric.readthedocs.io/en/latest/tutorial/compile.html](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/compile.html?ref=graphusergroup.com)
  
  compile ê¸°ëŠ¥: torch codeë¥¼ jittable(just-in-time)í•˜ê²Œ í•´ì¤Œ
  
  - interprete â†’ compileë¡œ ë³€í™˜í•´ì¤Œìœ¼ë¡œì¨ ì¢€ ë” ê¸°ê³„ê°€ ì½ê¸° ì‰½ê²Œ ì½”ë“œë¥¼ ë²ˆì—­í•´ ì¤Œ
  - ë¬´ë ¤ 300ë°° ê°€ê¹Œì´ ì„±ëŠ¥ ê°œì„ ì„ ì´ë¤„ëƒˆë‹¤ê³  í•©ë‹ˆë‹¤.
  
  **ReFresh: Reducing Memory Access from Exploiting Stable Historical Embeddings for Graph Neural Network Training** [[https://arxiv.org/pdf/2301.07482.pdf](https://arxiv.org/pdf/2301.07482.pdf?ref=graphusergroup.com)]
  
  GNN ì—ì„œ cost ê°€ ë§ì´ ë°œìƒí•˜ëŠ” ì—¬ëŸ¬ ìš”ì†Œë“¤ ì¤‘ í•˜ë‚˜ì¸ mini-batching ì„ ê°œì„ í•˜ê³ ì embeddingë§ˆë‹¤ tagging(cache)ì„ í™œìš©í•´ì„œ costë¥¼ ì¤„ì´ê³ ì ì‹œë„í•œ ë…¼ë¬¸
  
  - difficulty in training large-scale GNN, motivationë¶€í„° ì–´ë–»ê²Œ í•´ê²°í• ê²ƒì¸ê°€ì— ëŒ€í•´ ë…¼ë¦¬ ì „ê°œê°€ ì˜ ë˜ì–´ ìˆëŠ” ë…¼ë¬¸
  - í•œ ë²ˆ í†µë…í•´ë³´ì‹œëŠ”ê²ƒì„ ê°•ë ¥ ì¶”ì²œ
  
  **Finally, a Fast Algorithm for Shortest Paths on Negative Graphs** [[https://www.quantamagazine.org/finally-a-fast-algorithm-for-shortest-paths-on-negative-graphs-20230118](https://www.quantamagazine.org/finally-a-fast-algorithm-for-shortest-paths-on-negative-graphs-20230118?ref=graphusergroup.com)]
  
  í˜„ì¬ graphê°€ ê°€ì¥ ì˜ í™œìš©ë˜ëŠ” ë¶„ì•¼ ì¤‘ í•˜ë‚˜ê°€ ë°”ë¡œ navigation ë¶„ì•¼. ì¶œë°œ ì§€ì ê³¼ ë„ì°© ì§€ì  ì‚¬ì´ì˜ ìµœì ê±°ë¦¬ë¥¼ ì°¾ëŠ”ê²Œ ë°”ë¡œ shortest path of graph theory ë¬¸ì œë¡œë„ ë°”ë¼ ë³¼ ìˆ˜ ìˆê¸° ë•Œë¬¸.
  
  edgeì˜ weightê°’ ì„¤ì • ì‹œ ì–‘ê³¼ ìŒì— ëŒ€í•´ ëª¨ë‘ ê³ ë ¤í•´ì•¼í•˜ëŠ” ìƒí™©ê¹Œì§€ ê³ ë ¤ ê°€ëŠ¥í•œ ì•Œê³ ë¦¬ì¦˜ ì œì‹œ
  
  - ì €ë°€ë„ ë¶„í•´(tightly-connected) ì™€ ìœ ì‚¬í•œ ë°©í–¥ ê·¸ë˜í”„ì— ëŒ€í•œ í”„ë™ì²˜ë§ ì ˆì°¨ë¥¼ ê°œë°œ
  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 3ì›” 5ì£¼ì°¨</b></summary>
<div markdown="1">

  **The dynamic nature of percolation on networks with triadic interactions**
    
  ë„¤íŠ¸ì›Œí¬ ê³¼í•™ì—ì„œ í¼ì½œë ˆì´ì…˜(percolation)ì€ ë…¸ë“œ ë˜ëŠ” ì—ì§€ê°€ ì œê±°ë˜ê±°ë‚˜ ì¶”ê°€ë  ë•Œ ë„¤íŠ¸ì›Œí¬ì˜ ë™ì‘ì„ ì°¸ì¡°í•˜ëŠ” ê°œë…ì…ë‹ˆë‹¤. íŠ¹íˆ, ì¹¨íˆ¬ ì´ë¡ ì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë…¸ë“œ ë˜ëŠ” ì—ì§€ë¥¼ ì œê±°í•˜ëŠ” ê²ƒì´ ë„¤íŠ¸ì›Œí¬ì—ì„œ ê°€ì¥ í° ì—°ê²° êµ¬ì„± ìš”ì†Œì˜ í¬ê¸°ì™€ ì—°ê²°ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì—°êµ¬í•©ë‹ˆë‹¤.
  
  - percolationí•˜ë©´ ë– ì˜¤ë¥´ëŠ” ë¶„ì•¼ê°€ ë‹¤ì–‘í•˜ê² ì§€ë§Œ, ì €ëŠ” ê·¸ ì¤‘ ì´ì»¤ë¨¸ìŠ¤ê°€ ê°€ì¥ ë¨¼ì € ë– ì˜¤ë¥´ë„¤ìš”. í•„ìˆ˜ì¬ì¸ íœ´ì§€ ë¬¼ ë“±ê³¼ ê°™ì€ ë¬¼í’ˆë“¤ì€ ìˆ˜ìš”ê³µê¸‰ì´ ì¼ì •í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆëŠ” ë°˜ë©´, ìœ í–‰ì— ë§ì´ ì¢Œì§€ìš°ì§€ ë˜ëŠ” ë¬¼í’ˆ ê°™ì€ ê²½ìš°ì—ëŠ” ìˆ˜ìš”ê³µê¸‰ ë³€ë™ì„±ì´ í¬ê¸°ì— ì´ë¥¼ ë¹ ë¥´ê²Œ íŒŒì•…í•´ì„œ ì¤€ë¹„í•˜ëŠ”ê²Œ ê¸°ì—…ì˜ í•µì‹¬ ì—­ëŸ‰ì´ë¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íë¦„ì„ ì´ì»¤ë¨¸ìŠ¤ ê·¸ë¦¬ê³  ì¶”ì²œì‹œìŠ¤í…œì— ì ìš©ì„ í•´ë³¸ë‹¤ë©´, ìœ ì €ë“¤ì˜ ì–¸ê¸‰ì´ ë§ì•„ì§€ëŠ” ì•„ì´í…œ(percolationì´ ë†’ì€ ì•„ì´í…œ)ì„ ê°€ì¤‘ì¹˜ë¡œ ë”¥ëŸ¬ë‹ ê³„ì¸µì— ì¶”ê°€í•´ì¤€ë‹¤ë©´ ì„±ëŠ¥ ê°œì„ ì´ ë„ì›€ì´ ë˜ì§€ ì•Šì„ê¹Œ í•˜ëŠ” ìƒê°ì´ ë“œë„¤ìš”.
  
  **Creating generalizable downstream graph models with random projections** [[https://mlog-workshop.github.io/papers/wsdm23/2023-WSDM-MLoG-Creating_Generalizable_Downstream_Graph_Models_with_Random_Projections.pdf](https://mlog-workshop.github.io/papers/wsdm23/2023-WSDM-MLoG-Creating_Generalizable_Downstream_Graph_Models_with_Random_Projections.pdf?ref=graphusergroup.com)]
  
  featureë¥¼ ê³ ë ¤ì¹˜ ì•Šê³  ê·¸ë˜í”„ êµ¬ì¡°ë§Œì„ ê°€ì§€ê³  ì„ë² ë”©ì„ í•˜ê²Œ ëœë‹¤ë©´ ì•ì„œ ë§ì”€ë“œë¦° task-agnostic availableì´ ê°€ëŠ¥í• ê¹Œìš”? ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê·¸ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µí•´ë³´ê³ ì 1.graph structural algorithm 2. graph invariant feature 3. graph neural network ê°ê° ì„¸ê°€ì§€ ê´€ì ìœ¼ë¡œ ì ‘ê·¼
  
  - ë°ì´í„° ë¶„ì„ëŒ€íšŒì—ì„œ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ í™œìš©í•˜ë˜ node2vecì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ìˆ˜ ìˆëŠ” ë°©ì•ˆì´ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.
  - conv1d ì˜ ì¥ì ì„ í™œìš©í•˜ì—¬ clssifier ë¡œì¨ í™œìš©í•´ë³´ì•˜ìŠµë‹ˆë‹¤. signal processing classifier ì—ì„œ ì£¼ë¡œ í™œìš©ë˜ë˜ conv1d ë¥¼ invariant , spectral ê´€ì ì—ì„œ ì ‘ê·¼í•˜ë©´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ê²ƒì´ë¼ëŠ” ìƒìƒì´ í˜„ì‹¤ë¡œ ë˜ëŠ” ë…¼ë¬¸ì´ì˜€ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.
  
  **Efficiently Leveraging Multi-level User Intent for Session-based Recommendation via Atten-Mixer Network** [[https://arxiv.org/pdf/2206.12781.pdf](https://arxiv.org/pdf/2206.12781.pdf?ref=graphusergroup.com)]
  
  ìš”ì•½: Session permutation invariant ë¥¼ ìœ„í•´ í™œìš©í•œ Deepset algorithm
  
  Session-based GNN ì•Œê³ ë¦¬ì¦˜ì˜ ì£¼ íŠ¹ì„±ì´ë¼ ë³¼ ìˆ˜ ìˆëŠ” module by module weight flowì— ëŒ€í•´ ì‹¤ì¦ë¶„ì„ í•œ í›„, ê·¸ ë¶„ì„ìœ¼ë¡œ ë¶€í„° ì–»ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Atten-Mixerë¼ëŠ” ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„
  
  - í•µì‹¬ ë¬¸ì œì¸ Sparsificationë¥¼ ì™„í™”ì‹œí‚¤ë ¤ëŠ” ì‹œë„
  - session-based recommender system ê´€ë ¨í•´ì„œ ë‹¤ë“¤ ê¶ê¸ˆí•´í•˜ì…¨ì„ë§Œí•œ ì£¼ì œë“¤ì— ëŒ€í•´ ì˜ ë‹¤ë£¨ì–´ ë†“ì€ ë…¼ë¬¸ì´ë¼ ìƒê°. ì„œë² ì´ ë…¼ë¬¸ì„ ë³´ê¸°ë³´ë‹¤ ë³¸ ë…¼ë¬¸ì„ ë³´ë©° session GNNì— ê´€í•´ ì ‘ê·¼í•˜ì‹œë©´ í›¨ì”¬ ë°©í–¥ì„± ì¡ê¸°ì— ìˆ˜ì›”í•˜ì§€ ì•Šì„ê¹Œ ì‹¶ìŠµë‹ˆë‹¤.
  <br>
</div>
</details>

í˜„ì¬ ì—¬ê¸°ê¹Œì§€ í›‘ì–´ë³¸ ìƒíƒœì…ë‹ˆë‹¤.
<br>

<details>
<summary><b>23ë…„ 4ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 4ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 4ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 4ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">
    
  **Scalable Spatio-temporal Graph Neural Networks** [[https://arxiv.org/pdf/2209.06520.pdf](https://arxiv.org/pdf/2209.06520.pdf?ref=graphusergroup.com)]
  
  spatio-temporal GNNì—ì„œ í° í•œê³„ì ì´ì—ˆë˜ spatio-temporal feature trainingì—ì„œ ë°œìƒí•˜ëŠ” ë§‰ëŒ€í•œ ì—°ì‚°ëŸ‰ ì ˆê°ì„ ìœ„í•´ ì ‘ëª©í•œ ë°©ì‹ ESN(Echo State Network)
  
  **Graph Neural Networks Designed for Different Graph Types: A Survey** [[https://openreview.net/pdf?id=h4BYtZ79uy](https://openreview.net/pdf?id=h4BYtZ79uy&ref=graphusergroup.com)]
  
  ê·¸ë˜í”„ ì¢…ë¥˜ë§ˆë‹¤ì˜ ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ì‹ì— ëŒ€í•œ survey ë…¼ë¬¸
  
  - 1. ê·¸ë˜í”„ ë°ì´í„° ê°œìš”ë¶€í„° ì‹œì‘í•´ì„œ 2. GNNì— ëŒ€í•œ ê°œìš”, 3. ê° ê·¸ë˜í”„ ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ ì ìš©í•  ì‹œë‚˜ë¦¬ì˜¤ 4. ê·¸ë˜í”„ ë°ì´í„°ì— ê±¸ë§ì€ GNN ëª¨ë¸ ëª¨ë“  ê²Œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆìŒ
  - Graph Model Problem Data category 4ê°€ì§€ í•„ìˆ˜ì ì¸ ìš”ì†Œë“¤ë§Œ ì˜ ê°„ì¶”ë ¤ë†“ì€ í…Œì´ë¸”
  
  GNN, Graph data ì—°ê³„í•˜ì—¬ ì—°êµ¬í•˜ëŠ” ë¶„ë“¤ì—ê²Œ ê¼­ ì¶”ì²œí•˜ëŠ” ì„œë² ì´ ë…¼ë¬¸
  
  **Higher order assortativity for directed weighted networks and Markov chains** [[https://arxiv.org/pdf/2304.01737.pdf](https://arxiv.org/pdf/2304.01737.pdf?ref=graphusergroup.com)]
  
  higher order graph(hypergraph) ë¡œ ê°€ì •í•œ ìƒí™©(trade network)ì—ì„œ ì–´ë–¤ ì‹ìœ¼ë¡œ assortativity ë¥¼ ì¸¡ì •í•˜ëŠ”ì§€ì— ëŒ€í•´ ì´ì•¼ê¸°í•œ ë…¼ë¬¸
  
  **Getting started with PyTorch Geometric (PyG) on Graphcore IPUs** [[https://medium.com/graphcore/getting-started-with-pytorch-geometric-pyg-on-graphcore-ipus-9e842a0bac1e](https://medium.com/graphcore/getting-started-with-pytorch-geometric-pyg-on-graphcore-ipus-9e842a0bac1e?ref=graphusergroup.com)]
  
  IPUë¥¼ í™œìš©í•˜ì—¬ TPU, GPUì˜ í•œê³„ ê·¹ë³µ
  <br>
</div>
</details>
    
<details>
<summary><b>23ë…„ 5ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 5ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 5ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 5ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 6ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 6ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 6ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 6ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 7ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 7ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 7ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 7ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 8ì›” 1ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 8ì›” 2ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 8ì›” 3ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

<details>
<summary><b>23ë…„ 8ì›” 4ì£¼ì°¨</b></summary>
<div markdown="1">

  <br>
</div>
</details>

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/

